{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74038ba1-3abc-435e-b832-65d207c2d8cc",
   "metadata": {},
   "source": [
    "# Chinese characters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ef7f93-d7c8-4f43-a286-39130c6d0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "\n",
    "def stats(series):\n",
    "    print('    | %5s | %6s | %6s |' % ('Level', 'New', 'Total'))\n",
    "    print('    | ----- | ------ | ------ |')\n",
    "    tot = 0\n",
    "    assert len(set(series.index)) == len(series)\n",
    "    for g, cnt in series.value_counts().sort_index().items():\n",
    "        tot += cnt\n",
    "        print('    | %5s | %6d | %6d |' % (g, cnt, tot))\n",
    "\n",
    "def word_to_char_list(trad, level):\n",
    "    res = {}\n",
    "    ign = set()\n",
    "    for l,i,w in sorted([(l,i,w) for (i,(w,l)) in enumerate(zip(trad, level))]):\n",
    "        for c in w:\n",
    "            if ord(c) < 256 or c in '（）。？！…、，＝': continue\n",
    "            if ord(c) < 0x4E00:\n",
    "                ign.add(c)\n",
    "                continue\n",
    "            res[c] = min(res.get(c, l), l)\n",
    "    res = pd.Series(res, name='level').rename_axis('char')\n",
    "    if ign:\n",
    "        print('Ignored:', ''.join(ign))\n",
    "    return res\n",
    "\n",
    "unihan_df = pd.read_csv('../unihan/unihan.csv',  dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b1ba37-a433-41e4-8d0a-7efc3ef93747",
   "metadata": {},
   "source": [
    "## Traditional (TW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0abded-542b-4f2b-8d5d-393e652ccd6d",
   "metadata": {},
   "source": [
    "**`tocfl.csv`: characters by TOCFL 2022/2023 wordlist levels**\n",
    "- TOCFL level at which a character appears in the wordlist.\n",
    "- 2562 characters over 6 levels L0=Novice(pre-A1), L1..L5=CEFR A1/A2/B1/B2/C1+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1266ea-03ab-43db-a628-f5166cb7fdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     0 |    375 |    375 |\n",
      "    |     1 |    247 |    622 |\n",
      "    |     2 |    267 |    889 |\n",
      "    |     3 |    447 |   1336 |\n",
      "    |     4 |    629 |   1965 |\n",
      "    |     5 |    597 |   2562 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../tocfl/tocfl.csv')\n",
    "tocfl = word_to_char_list(df.Traditional, df.ID.str.slice(1, 2))\n",
    "tocfl.to_csv('tocfl.csv')\n",
    "stats(tocfl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc11d698-e5dc-4ac0-bbff-2dc736174c7c",
   "metadata": {},
   "source": [
    "**`tocfl-2018.csv`: characters by TOCFL 2018 wordlist levels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce239228-1a73-42d2-949b-dc357dc63f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     0 |    326 |    326 |\n",
      "    |     1 |    162 |    488 |\n",
      "    |     2 |    298 |    786 |\n",
      "    |     3 |    518 |   1304 |\n",
      "    |     4 |    633 |   1937 |\n",
      "    |     5 |    618 |   2555 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../tocfl/tocfl-2018.csv')\n",
    "tocfl = word_to_char_list(df.Traditional, df.ID.str.slice(1, 2))\n",
    "tocfl.to_csv('tocfl-2018.csv')\n",
    "stats(tocfl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9dbc35-451e-438a-8c09-c8a024ffbf11",
   "metadata": {},
   "source": [
    "**`cccc.csv`: characters by CCCC 2022 wordlist levels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87a80d2-975b-46d2-8475-ac71bc0691fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     0 |    462 |    462 |\n",
      "    |     1 |    299 |    761 |\n",
      "    |     2 |    285 |   1046 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../tocfl/cccc.csv')\n",
    "cccc = word_to_char_list(df.Traditional, df.ID.str.slice(1, 2))\n",
    "cccc.to_csv('cccc.csv')\n",
    "stats(cccc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2866258-30f3-4196-907b-11d24b9a2a4e",
   "metadata": {},
   "source": [
    "**`tbcl-chars.csv`: characters by TBCL character level**\n",
    "  - From their official character list: https://coct.naer.edu.tw/TBCL/\n",
    "  - 3133 characters (including variants) / 3100 excl. variants in original list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992018f5-51bd-456b-a0c1-98921bf26941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     1 |    249 |    249 |\n",
      "    |     2 |    262 |    511 |\n",
      "    |     3 |    300 |    811 |\n",
      "    |     4 |    507 |   1318 |\n",
      "    |     5 |    604 |   1922 |\n",
      "    |     6 |    607 |   2529 |\n",
      "    |     7 |    604 |   3133 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../tbcl/chars-expanded.csv', dtype='str')\n",
    "tbcl_chars = word_to_char_list(df.char, df.Level.str.slice(0, 1))\n",
    "tbcl_chars.to_csv('tbcl-chars.csv')\n",
    "stats(tbcl_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128cb553-cd57-49c4-9f63-0ad4b7cca7cb",
   "metadata": {},
   "source": [
    "**`tbcl-words.csv`: characters by TBCL wordlist level**\n",
    "  - TBCL word level at which a character appears in a wordlist.\n",
    "  - Note it's a bit different from their official character lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dadf4d08-53c5-4bf3-9a96-1348a1660c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     1 |    361 |    361 |\n",
      "    |     2 |    263 |    624 |\n",
      "    |     3 |    264 |    888 |\n",
      "    |     4 |    532 |   1420 |\n",
      "    |     5 |    647 |   2067 |\n",
      "    |     6 |    764 |   2831 |\n",
      "    |     7 |    743 |   3574 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../tbcl/tbcl-expanded.csv', dtype='str')\n",
    "tbcl_words = word_to_char_list(df.Traditional, df.Level.str.slice(0, 1)).to_frame()\n",
    "tbcl_words['in_tbcl_chars'] = tbcl_words.index.isin(tbcl_chars.index).astype(int)\n",
    "tbcl_words.to_csv('tbcl-words.csv')\n",
    "stats(tbcl_words.level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cccdc22d-3ac9-40ed-a64b-9b012c9e04c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'豚喬鶯膿曹綵霞菇値痔橡痘麪芹趾蠶痰荔璧渣藻茉遛昌飩栗猿踪饗劉勘鋁弘妮鑒埔褒槳亭糯萍蟬甄弧蝸洛婷萱鈣嘛閩嘍簿呂韓峯淤蕾齋棕鳩橙絮涮范朶鑄睏矇盧贓鮪刨蔣糗耶鉢眞粵凱芋矢蛀芭餡磁楓昭趙尼笛硯蜀雛餛却痣擧娟烟燴垢郭欸礁鷄億蜘莉躱擂缽疹烘嬸澳蓓楊孟洲篆魷啓俄吳鵲柚菠纜岔愼蘇粧蚵荐强牀魏跛臘砥菲礪箏鯨砂彥'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In TBCL chars but not words..?\n",
    "''.join(set(tbcl_chars.index)-set(tbcl_words.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952dbaf7-95fd-41ef-83b0-e5bce4dd40eb",
   "metadata": {},
   "source": [
    "**`dangdai.csv`, `modernchinese.csv`, `pavc.csv`: characters in taiwanese Mandarin textbooks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682563ce-d941-4ffd-a4f5-5c2d2aacb0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     1 |    491 |    491 |\n",
      "    |     2 |    382 |    873 |\n",
      "    |     3 |    396 |   1269 |\n",
      "    |     4 |    318 |   1587 |\n",
      "    |     5 |    231 |   1818 |\n",
      "    |     6 |    235 |   2053 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../dangdai/dangdai.csv')\n",
    "dangdai = word_to_char_list(df.Traditional, df.ID.str.slice(1, 2))\n",
    "dangdai.to_csv('dangdai.csv')\n",
    "stats(dangdai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3bf4993-830f-46b1-a00f-bf7c99b80d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     1 |    656 |    656 |\n",
      "    |     2 |    401 |   1057 |\n",
      "    |     3 |    323 |   1380 |\n",
      "    |     4 |    297 |   1677 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../modernchinese/modernchinese.csv')\n",
    "modernchinese = word_to_char_list(df.Traditional, df.ID.str.slice(1, 2))\n",
    "modernchinese.to_csv('modernchinese.csv')\n",
    "stats(modernchinese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2541bb93-9da9-4557-9fb0-edd64cc1e97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     1 |    346 |    346 |\n",
      "    |     2 |    336 |    682 |\n",
      "    |     3 |    692 |   1374 |\n",
      "    |     4 |    454 |   1828 |\n",
      "    |     5 |    433 |   2261 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../pavc/pavc.csv')\n",
    "df = df[df.Meaning.str.contains('PAVC-')]\n",
    "df['level'] = [min(re.findall('PAVC-(.)', s)) for s in df.Meaning]\n",
    "pavc = word_to_char_list(df.Traditional, df.level)\n",
    "pavc.to_csv('pavc.csv')\n",
    "stats(pavc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd4f8b7-1ef2-4c82-aa14-514e760e7487",
   "metadata": {},
   "source": [
    "**`tw.csv`: characters by taiwanese school textbooks grade**\n",
    "  - From https://web.archive.org/web/20111215143140/http://residence.educities.edu.tw/wei3128/currinstruc/wordclause/generwordgrd9.htm\n",
    "  - https://chinese.stackexchange.com/questions/6200/table-of-chinese-characters-taught-in-primary-school-grouped-by-grade\n",
    "  - Based on textbooks content analysis, otherwise no official/government source for this.\n",
    "  - 5568 characters over 9 grades\n",
    "  - Related study: [國立臺中教育大學語文教育研究所碩士論文](https://ntcuir.ntcu.edu.tw/bitstream/987654321/6530/1/098NTCTC461033-001.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1656afe7-a46d-41e5-8d51-fc4440cf39d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一級通用字彙【共198個】\n",
      "第二級通用字彙【共166個】\n",
      "第三級通用字彙【共267個】\n",
      "第四級通用字彙【共351個】\n",
      "第五級通用字彙【共421個】\n",
      "第六級通用字彙【共548個】\n",
      "第七級通用字彙【共616個】\n",
      "第八級通用字彙【共956個】\n",
      "第九級通用字彙【共2042個】\n",
      "expected 5565\n",
      "\n",
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     1 |    198 |    198 |\n",
      "    |     2 |    175 |    373 |\n",
      "    |     3 |    266 |    639 |\n",
      "    |     4 |    350 |    989 |\n",
      "    |     5 |    420 |   1409 |\n",
      "    |     6 |    547 |   1956 |\n",
      "    |     7 |    615 |   2571 |\n",
      "    |     8 |    955 |   3526 |\n",
      "    |     9 |   2042 |   5568 |\n"
     ]
    }
   ],
   "source": [
    "src = 'data/tw-wei3128.txt'\n",
    "if os.path.exists(src):\n",
    "    tw = {}\n",
    "    lv = 0\n",
    "    k = 0\n",
    "\n",
    "    for line in open(src):\n",
    "        line = line.strip()\n",
    "        if m := re.search('第.級通用字彙.*共([0-9]+)個', line):\n",
    "            lv += 1\n",
    "            print(line)\n",
    "            k += int(m[1])\n",
    "        elif lv >= 1:\n",
    "            for c in line:\n",
    "                if ord(c) < 256 or c in ' 、': continue\n",
    "                assert c not in tw, (line,c)\n",
    "                tw[c] = lv\n",
    "            #print(lv, line, len([c for c in tw if tw[c]==lv]))\n",
    "\n",
    "    print('expected %d\\n' % k)\n",
    "\n",
    "    tw = pd.Series(tw, name='level').rename_axis('char')\n",
    "    tw.to_csv('tw.csv')\n",
    "\n",
    "    stats(tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd6da9-49aa-496b-9ea7-3524f9ccddc0",
   "metadata": {},
   "source": [
    "## Traditional (HK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d808f-dc8f-45c6-b699-3c9f04525558",
   "metadata": {},
   "source": [
    "**`hk-unihan.csv`: characters by Hong Kong primary grade level from Unihan's kGradeLevel (incomplete)**\n",
    "- https://www.unicode.org/reports/tr38/#kGradeLevel\n",
    "- Note Unihan has a very incomplete list, e.g. 書 missing\n",
    "- Current reference seems to be \"香港小學學習字詞表\" with 3171 characters.\n",
    "  - https://www.edbchinese.hk/lexlist_ch/\n",
    "  - Only two levels per char? KS1 / KS2\n",
    "  - Non graded list https://zh-tw.sayjack.com/chinese/traditional-chinese/hk3171/level:3171/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dc73e97-c768-4d7d-83a1-db482c0f8d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     1 |    460 |    460 |\n",
      "    |     2 |    510 |    970 |\n",
      "    |     3 |    543 |   1513 |\n",
      "    |     4 |    598 |   2111 |\n",
      "    |     5 |    259 |   2370 |\n",
      "    |     6 |    262 |   2632 |\n"
     ]
    }
   ],
   "source": [
    "df = unihan_df[unihan_df.kGradeLevel.notnull()]\n",
    "hk = word_to_char_list(df.char, df.kGradeLevel)\n",
    "hk.to_csv('hk-unihan.csv')\n",
    "stats(hk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aee262-b2e6-4d57-bca4-e5c9eadc06c9",
   "metadata": {},
   "source": [
    "**`hk-3171.csv`: current HK primary school list**\n",
    "  - 香港小學學習字詞表\n",
    "  - https://www.edbchinese.hk/lexlist_ch/\n",
    "  - https://zh-tw.sayjack.com/chinese/traditional-chinese/hk3171/level:3171/\n",
    "  - 3171 characters, no levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "788d291e-56a3-4892-b301-9fb7d1af378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     0 |   3171 |   3171 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hk-3171.csv').set_index('char')\n",
    "stats(df.level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c95b9c2-d4d6-49ad-b273-0c003c8f3646",
   "metadata": {},
   "source": [
    "## Simplified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c27889-acb6-4f16-9d24-8f6385fbfe1b",
   "metadata": {},
   "source": [
    "**`tgh.csv`: [Table of General Standard Chinese Characters](https://en.wikipedia.org/wiki/Table_of_General_Standard_Chinese_Characters) ([通用规范汉字表](https://www.gov.cn/gzdt/att/att/site1/20130819/tygfhzb.pdf), Tōngyòng Guīfàn Hànzì Biǎo).**\n",
    "  - Official standard list of common simplified characters by PRC's Ministry of Education (2013), latest such standard currently.\n",
    "  - Data from [Unihan](https://www.unicode.org/reports/tr38/#kTGH) database, including pinyin readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2850e8e-2b7b-49eb-8df8-c046b1ad5403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     1 |   3500 |   3500 |\n",
      "    |     2 |   3000 |   6500 |\n",
      "    |     3 |   1605 |   8105 |\n"
     ]
    }
   ],
   "source": [
    "# From Unihan database incl. pinyin\n",
    "df = unihan_df[lambda X: X.kTGH.notnull()][['char', 'kTGH', 'kTGHZ2013', 'kIRG_GSource']].copy()\n",
    "df['tgh_index'] = df.kTGH.str.extract('^20[0-9]{2}:([1-9][0-9]{0,3})$').astype(int)\n",
    "df['level'] = 3\n",
    "df.loc[df['tgh_index'] <= 6500, 'level'] = 2\n",
    "df.loc[df['tgh_index'] <= 3500, 'level'] = 1\n",
    "df['pinyin'] = [re.sub(r' *[0-9]{3}\\.[0-9]{3}(,[0-9]{3}\\.[0-9]{3})*:', ' ', s).strip() for s in df.kTGHZ2013]\n",
    "df = df[['char', 'level', 'tgh_index', 'pinyin']].sort_values('tgh_index').reset_index(drop=True)\n",
    "assert len(df) == 8105 and list(df.tgh_index) == list(range(1, 8105+1))\n",
    "tgh_df = df\n",
    "tgh = tgh_df.set_index('char').level\n",
    "tgh_df.to_csv('tgh.csv', index=False)\n",
    "stats(tgh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef8c26a-da70-4d32-9a1f-f67f006f51ca",
   "metadata": {},
   "source": [
    "**`hsk30.csv`: characters in HSK 3.0 wordlist by level at which they first appear**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f42432d-a511-4fc3-b614-7042e675f5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored: 〇\n",
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     1 |    300 |    300 |\n",
      "    |     2 |    300 |    600 |\n",
      "    |     3 |    300 |    900 |\n",
      "    |     4 |    300 |   1200 |\n",
      "    |     5 |    300 |   1500 |\n",
      "    |     6 |    300 |   1800 |\n",
      "    |   7-9 |   1171 |   2971 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../hsk30/hsk30-expanded.csv')\n",
    "hsk30 = word_to_char_list(df.Simplified, df.Level)\n",
    "hsk30.to_csv('hsk30.csv')\n",
    "stats(hsk30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b98f734-f09e-4d53-bf41-6d114ed74d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tgh_level\n",
       "1    2938\n",
       "2      33\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Almost all from TGH level 1:\n",
    "hsk30_df = hsk30.to_frame()\n",
    "hsk30_df['tgh_level'] = [tgh[c] for c in hsk30_df.index]\n",
    "hsk30_df.tgh_level.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5d3fc8-b9c1-461d-9d60-6dd2ea8e33d6",
   "metadata": {},
   "source": [
    "**`cn2460.csv`: random unofficial list \"小学1-6年级生字表\" from the internet**\n",
    "  - Simplified characters by 6 primary school grades.\n",
    "  - Mostly TGH level 1 characters with a few dozen level 2 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cba3b803-e17d-43e6-bd5d-cf5c052347b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution by TGH level:\n",
      "1    2424\n",
      "2      43\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     1 |    347 |    347 |\n",
      "    |     2 |    640 |    987 |\n",
      "    |     3 |    594 |   1581 |\n",
      "    |     4 |    398 |   1979 |\n",
      "    |     5 |    297 |   2276 |\n",
      "    |     6 |    191 |   2467 |\n"
     ]
    }
   ],
   "source": [
    "src = 'data/cn2460.txt'\n",
    "if os.path.exists(src):\n",
    "    xx = {}\n",
    "    lv = 0\n",
    "    k = 0\n",
    "    tgh_py = tgh_df.set_index('char').pinyin.to_dict()\n",
    "    for line in open(src):\n",
    "        line = line.strip()\n",
    "        #print(line)\n",
    "        if m := re.match('(.)年级(上|下).*： *([0-9]+)个.*',line):\n",
    "            if m[2] == '上': lv += 1\n",
    "            #print(lv, line)\n",
    "            k += int(m[3])\n",
    "        elif lv >= 1:\n",
    "            line = re.sub('^[0-9]+ *、', '', line).strip()\n",
    "            line = line.replace(')', ') ')\n",
    "            for part in line.split():\n",
    "                m = re.match(r'^(.)\\(([^) ]+)\\)$', part)\n",
    "                assert m, line\n",
    "                c, py = m[1], m[2]\n",
    "                if c in xx and xx[c] != lv:\n",
    "                    #print('  Repeated %c from level %d' % (c, xx[c]))\n",
    "                    continue\n",
    "                if c not in tgh_py:\n",
    "                    #print('  Ignoring non-TGH char: %c' % c)\n",
    "                    continue\n",
    "                #if py not in tgh_py[c].split():\n",
    "                #    print('  Pinyin for %s [%s] != TGH [%s]' % (c, py, tgh_py[c]))\n",
    "                xx[c] = lv\n",
    "            #print(lv, line, len([c for c in xx if xx[c]==lv]))\n",
    "\n",
    "    xx = pd.Series(xx, name='level').sort_values().rename_axis('char')\n",
    "    xx.to_csv('cn2460.csv')\n",
    "    #print('Expected %d\\n' % k)\n",
    "\n",
    "    print('Distribution by TGH level:')\n",
    "    print(pd.Series([tgh.loc[c] for c in set(xx.index)]).value_counts(), '\\n')\n",
    "\n",
    "    stats(xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dea927d-e0c5-4a56-8be4-07bf6296c834",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfcac28-55ca-4e95-815b-c2088031a717",
   "metadata": {},
   "source": [
    "**`kanji.csv`: japanese kanji by school grade level.**\n",
    "- Not exactly chinese, but close to traditional characters, with levels specified by government.\n",
    "- Grade levels (2020) from [wikipedia](https://en.wikipedia.org/wiki/List_of_j%C5%8Dy%C5%8D_kanji), characters cross-referenced against Unihan's kJoyoKanji.\n",
    "- 2136 characters ([jōyō kanji](https://en.wikipedia.org/wiki/List_of_j%C5%8Dy%C5%8D_kanji)) over 6 elementary school grades ([kyōiku kanji](https://en.wikipedia.org/wiki/Ky%C5%8Diku_kanji)) + 1110 secondary school kanji.\n",
    "- https://en.wikipedia.org/wiki/List_of_j%C5%8Dy%C5%8D_kanji\n",
    "- https://en.wikipedia.org/wiki/Ky%C5%8Diku_kanji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71de9eee-c346-4e67-96ab-f857eb315773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     1 |     80 |     80 |\n",
      "    |     2 |    160 |    240 |\n",
      "    |     3 |    200 |    440 |\n",
      "    |     4 |    202 |    642 |\n",
      "    |     5 |    193 |    835 |\n",
      "    |     6 |    191 |   1026 |\n",
      "    |     7 |   1110 |   2136 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_html('https://en.wikipedia.org/wiki/List_of_j%C5%8Dy%C5%8D_kanji')[2]\n",
    "df = df.rename(columns={\n",
    "    'New (Shinjitai)': 'shinjitai',\n",
    "    'Old (Kyūjitai)': 'kyujitai',\n",
    "    'Grade': 'level',\n",
    "})\n",
    "df['shinjitai'] = df.shinjitai.str.replace('\\xa0.*', '',regex=True)\n",
    "df['kyujitai'] = df.kyujitai.fillna('').str.replace('\\xa0.*', '',regex=True)\n",
    "df['level'] = df.level.str.replace('S', '7')\n",
    "assert set(df.shinjitai) == set(unihan_df[lambda X: X.kJoyoKanji == '2010'].char)\n",
    "df['char'] = df['shinjitai']\n",
    "df = df[['char', 'kyujitai', 'level']].set_index('char')\n",
    "df.to_csv('kanji.csv')\n",
    "df.level.value_counts().sort_index()\n",
    "kanji = df.level\n",
    "stats(kanji)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713bd965-90ae-4732-b3d1-e6bc97cbbc29",
   "metadata": {},
   "source": [
    "**`hanja.csv`: korean educational hanjas.**\n",
    "  - https://en.wikipedia.org/wiki/Basic_Hanja_for_educational_use\n",
    "  - Characters from Unihan's kKoreanEducationHanja, grades and some variant characters from [wikipedia](https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD_%EC%A4%91%EA%B3%A0%EB%93%B1%ED%95%99%EA%B5%90_%EA%B8%B0%EC%B4%88%ED%95%9C%EC%9E%90_%EB%AA%A9%EB%A1%9D)\n",
    "  - 1800 characters over two levels (grade 7-9 / 10-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41ecca0d-0aa4-4f07-9ed8-265343cd58a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia missing: {'茲', '戲', '産', '晚'}\n",
      "wikipedia extra:   {'晩', '玆', '戱', '產'}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_html('https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD_%EC%A4%91%EA%B3%A0%EB%93%B1%ED%95%99%EA%B5%90_%EA%B8%B0%EC%B4%88%ED%95%9C%EC%9E%90_%EB%AA%A9%EB%A1%9D')[1]\n",
    "l1 = re.sub('[\\xa0 ·]', '', ''.join(df['중학교용'].fillna('')))\n",
    "l2 = re.sub('[\\xa0 ·]', '', ''.join(df['고등학교용'].fillna('')))\n",
    "assert len(l1) == len(set(l1)) == 900\n",
    "assert len(l2) == len(set(l2)) == 900\n",
    "assert len(set(l1+l2)) == 1800\n",
    "l1 = set(l1)\n",
    "l2 = set(l2)\n",
    "\n",
    "unihan = set(unihan_df[lambda X: X.kKoreanEducationHanja == '2007'].char)\n",
    "assert len(unihan) == 1800\n",
    "\n",
    "print('wikipedia missing:', unihan-(l1|l2))\n",
    "print('wikipedia extra:  ', (l1|l2)-unihan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cff0f386-b2ed-49d8-8876-81ee198ae4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | Level |    New |  Total |\n",
      "    | ----- | ------ | ------ |\n",
      "    |     1 |    900 |    900 |\n",
      "    |     2 |    900 |   1800 |\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for c in sorted(unihan):\n",
    "    variant = {'茲':'玆', '晚':'晩', '戲':'戱', '産':'產'}.get(c, '')\n",
    "    assert (c in l1 or variant in l1 or c in l2 or variant in l2)\n",
    "    rows.append({\n",
    "        'char': c,\n",
    "        'variant': variant,\n",
    "        'level': 1 if (c in l1 or variant in l1) else 2\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(['level', 'char']).set_index('char')\n",
    "df.to_csv('hanja.csv')\n",
    "hanja = df.level\n",
    "stats(hanja)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc119bb5-9b1a-40db-ab2a-e72e0fafeefd",
   "metadata": {},
   "source": [
    "**kanji/hanja vs trad/simp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3efd739b-cadb-441c-8b92-e99f9b80762b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trad 2113 / simp 4592 / common 3513\n",
      "kanji: trad 505 / simp 104 / common 1290 / other 237\n",
      "hanja: trad 632 / simp 4 / common 1129 / other 35\n"
     ]
    }
   ],
   "source": [
    "trad = set()\n",
    "for name in ['tocfl', 'tocfl-2018', 'cccc', 'tbcl-chars', 'tbcl-words', 'dangdai', 'modernchinese', 'pavc', 'tw']:\n",
    "    trad |= set(pd.read_csv(f'{name}.csv').char)\n",
    "simp = set(pd.read_csv('tgh.csv').char)\n",
    "cmn = trad & simp\n",
    "trad -= cmn\n",
    "simp -= cmn\n",
    "print('trad %d / simp %d / common %d' % (len(trad), len(simp), len(cmn)))\n",
    "print('kanji: trad %d / simp %d / common %d / other %d' % (len(set(kanji.index) & trad), len(set(kanji.index) & simp), len(set(kanji.index) & cmn), len(set(kanji.index) - (trad | simp | cmn))))\n",
    "print('hanja: trad %d / simp %d / common %d / other %d' % (len(set(hanja.index) & trad), len(set(hanja.index) & simp), len(set(hanja.index) & cmn), len(set(hanja.index) - (trad | simp | cmn))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
