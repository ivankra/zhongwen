{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c325e439-1711-4fde-b235-d44737f0187f",
   "metadata": {},
   "source": [
    "# TBCL parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b408022-558b-48ca-bc62-65a95f308751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, requests, io, urllib, json\n",
    "import pandas as pd\n",
    "import opencc\n",
    "\n",
    "pd.options.display.max_rows = 2000\n",
    "\n",
    "opencc_tw2s = opencc.OpenCC('tw2s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21d089-8a49-4d85-9fe4-9074c378efd4",
   "metadata": {},
   "source": [
    "Download files from TBCL home page: https://coct.naer.edu.tw/download/tech_report/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4006e880-016e-4064-9c68-86db698c0ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "![[ ! -d downloads && -d ../downloads/tbcl ]] && ln -s ../downloads/tbcl downloads\n",
    "!mkdir -p downloads\n",
    "\n",
    "if not os.path.exists('downloads/.done'):\n",
    "    home_url = 'https://coct.naer.edu.tw/download/tech_report/'\n",
    "    resp = requests.get(home_url).content.decode('utf-8')\n",
    "    for url in sorted(re.findall('<a href=\"([^\"]+[.](?:xlsx|docx))\"', resp)):\n",
    "        url = os.path.join(home_url, url)\n",
    "        !cd downloads && wget -nc \"{url}\"\n",
    "    !chmod a-w downloads/*.xlsx; touch downloads/.done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b97a5-dd71-4658-a388-a67edd7ac808",
   "metadata": {},
   "source": [
    "Symlinks for convenience and checksums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea40a07f-71a8-4786-8d2f-515c7ab61a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e92ac49c5bb203e16fea29c53a2b2cb790033fb332a699c7689adde21528b8f  affixes.xlsx\n",
      "6329e2516c5dbe416b85f6a94d200ebe95493f24f233a63dc10d85aa257a088f  chars.xlsx\n",
      "b6ce3747a06c8482ce5f4059689463de01a45d2b78707feb85917404ccffae62  glossary.xlsx\n",
      "c587989cf89992d55d97a2f932289ef071648ca80339ccfaff7bb823914e5bcf  grammar.xlsx\n",
      "cb16dcd262eb3e499273f972c9a3a404c40042a7def35631fc40b2a64dd50eb0  words.xlsx\n",
      "b6ce3747a06c8482ce5f4059689463de01a45d2b78707feb85917404ccffae62  臺灣華語文能力基準基礎詞彙表_111-09-20.xlsx\n",
      "6329e2516c5dbe416b85f6a94d200ebe95493f24f233a63dc10d85aa257a088f  臺灣華語文能力基準漢字表_111-09-20.xlsx\n",
      "cb16dcd262eb3e499273f972c9a3a404c40042a7def35631fc40b2a64dd50eb0  臺灣華語文能力基準詞語表_111-11-14.xlsx\n",
      "c587989cf89992d55d97a2f932289ef071648ca80339ccfaff7bb823914e5bcf  臺灣華語文能力基準語法點表_112-01-04.xlsx\n",
      "5e92ac49c5bb203e16fea29c53a2b2cb790033fb332a699c7689adde21528b8f  臺灣華語文能力基準類詞綴表_111-09-20.xlsx\n"
     ]
    }
   ],
   "source": [
    "%%bash -e\n",
    "cd downloads\n",
    "chmod a-w *.xlsx *.ods *.pdf\n",
    "ln -sf '臺灣華語文能力基準詞語表_111-11-14.xlsx' words.xlsx\n",
    "ln -sf '臺灣華語文能力基準詞語表_111-11-14.ods' words.ods\n",
    "ln -sf '臺灣華語文能力基準漢字表_111-09-20.docx' chars.docx\n",
    "ln -sf '臺灣華語文能力基準漢字表_111-09-20.xlsx' chars.xlsx\n",
    "ln -sf '臺灣華語文能力基準類詞綴表_111-09-20.docx' affixes.docx\n",
    "ln -sf '臺灣華語文能力基準類詞綴表_111-09-20.xlsx' affixes.xlsx\n",
    "ln -sf '臺灣華語文能力基準語法點表_112-01-04.xlsx' grammar.xlsx\n",
    "ln -sf '臺灣華語文能力基準語法點表_112-01-04.docx' grammar.docx\n",
    "ln -sf '臺灣華語文能力基準基礎詞彙表_111-09-20.xlsx' glossary.xlsx\n",
    "sha256sum *.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f2c66-8e66-4000-bf8e-06073ce37676",
   "metadata": {},
   "source": [
    "## Parse wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4d891e-73db-4fdb-ada0-c428284143e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glossary.csv: 1518 rows\n"
     ]
    }
   ],
   "source": [
    "glossary_df = pd.read_excel('downloads/glossary.xlsx').rename(columns={\n",
    "    '序號': 'ID',\n",
    "    '詞語': 'Traditional',\n",
    "    '注音': 'Zhuyin',\n",
    "    '漢拼': 'Pinyin',\n",
    "    '詞類/性質': 'POS',\n",
    "    '詞彙英譯': 'Meaning',\n",
    "    '語義/義項': 'Meaning2',\n",
    "    '用法-常用搭配詞': 'Compounds',\n",
    "    '例句': 'Examples',\n",
    "    '級別': 'Level',\n",
    "})\n",
    "assert list(glossary_df.ID - 1) == list(glossary_df.index)\n",
    "glossary_df['Level'] = glossary_df.Level.str.extract('^第([1-7][*]?)級$')[0]\n",
    "assert sum(glossary_df.Level.isnull()) == 0\n",
    "glossary_df.to_csv('glossary.csv', index=False)\n",
    "print('glossary.csv: %d rows' % len(glossary_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49e9d65-3ca3-4ab5-b761-5d333b65f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opencc_tw2s = opencc.OpenCC('tw2s')\n",
    "\n",
    "# Character levels from Table of General Standard Chinese Characters for verification.\n",
    "tgh_level = pd.read_csv('../chars/tgh.csv').set_index('char').level.to_dict()\n",
    "\n",
    "# Convert to simplified characters + verify\n",
    "def to_simplified(trad):\n",
    "    simp = opencc_tw2s.convert(trad)\n",
    "    for x, y in ('擡抬', '砲炮', '牠它', '妳你', '姪侄', '瞇眯', '舖铺', '搥捶', '暱昵', '瑯琅'):\n",
    "        simp = simp.replace(x, y)\n",
    "    if '/' in simp and len(set(simp.split('/'))) == 1:\n",
    "        simp = simp.split('/')[0]\n",
    "    for c in simp:\n",
    "        assert c in tgh_level or c in '/(),吋拚徬祂', (trad, simp, c)\n",
    "    return simp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3779144e-46c4-4ebe-9b67-9954ef91d4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unjoined glossary vocab: 1中國 1法國 3非洲 2瓶子/瓶瓶 3亞洲 1車/車子 1英國 3義大利 1臺灣/台灣 3韓國 1日本 1應該/應 3美洲 2德國 2罐 3歐洲 3月台/月臺 1美國 1還\n",
      "tbcl.csv: 14425 rows\n"
     ]
    }
   ],
   "source": [
    "VARIANTS_EXC = {\n",
    "    ('姊姊/姐姐/姊/姐', 'jiějie/jiě'): [['姊姊','jiějie'], ['姐姐','jiějie'], ['姊','jiě'], ['姐','jiě']],\n",
    "    ('那/那裡/那裏/那兒', 'nà/nàlǐ/nàr'): [['那', 'nà'], ['那裡', 'nàlǐ'], ['那裏', 'nàlǐ'], ['那兒', 'nàr']],\n",
    "    ('這/這裡/這裏/這兒', 'zhè/zhèlǐ/zhèr'): [['這', 'zhè'], ['這裡', 'zhèlǐ'], ['這裏', 'zhèlǐ'], ['這兒', 'zhèr']],\n",
    "    ('手錶/手表/錶/表', 'shǒubiǎo/biǎo'): [['手錶', 'shǒubiǎo'], ['手表', 'shǒubiǎo'], ['錶', 'biǎo'], ['表', 'biǎo']],\n",
    "    ('新台幣/新臺幣/台幣/臺幣', 'xīntáibì/táibì'): [['新台幣', 'xīntáibì'], ['新臺幣', 'xīntáibì'], ['台幣', 'táibì'], ['臺幣', 'táibì']],\n",
    "    ('慾望/欲望/慾', 'yùwàng/yù'): [['慾望', 'yùwàng'], ['欲望', 'yùwàng'], ['慾', 'yù']],\n",
    "    ('侄子/姪子/侄兒/姪兒', 'zhízi/zhír'): [['侄子', 'zhízi'], ['姪子', 'zhízi'], ['侄兒', 'zhír'], ['姪兒', 'zhír']],\n",
    "    ('嘴脣/嘴唇/脣/唇', 'zuǐchún/chún'): [['嘴脣', 'zuǐchún'], ['嘴唇', 'zuǐchún'], ['脣', 'chún'], ['唇', 'chún']],\n",
    "    ('沒(有)用', 'méi(yǒu)yòng'): [['沒用', 'méiyòng'], ['沒有用', 'méiyǒuyòng']],\n",
    "    ('一邊(兒)', 'yìbiān(r)'): [['一邊', 'yìbiān'], ['一邊兒', 'yìbiānr']],\n",
    "}\n",
    "\n",
    "def get_variants(vocab, pinyin):\n",
    "    vocab = vocab.strip()\n",
    "    pinyin = re.sub(' */ *', '/', pinyin.strip())\n",
    "\n",
    "    ps = re.sub('[^()/]', '', pinyin)\n",
    "    vs = re.sub('[^()/]', '', vocab)\n",
    "    if ps == '' and vs == '':\n",
    "        return []\n",
    "\n",
    "    if (vocab, pinyin) in VARIANTS_EXC:\n",
    "        return VARIANTS_EXC[(vocab, pinyin)]\n",
    "\n",
    "    if vs == '' and ps:\n",
    "        assert set(ps) == {'/'}\n",
    "        return [[vocab, p.strip()] for p in pinyin.split('/')]\n",
    "\n",
    "    if vs and ps == '':\n",
    "        assert set(vs) == {'/'}\n",
    "        assert len(set(map(len, vocab.split('/')))) == 1, vocab  # all terms same length\n",
    "        return [[v, pinyin] for v in vocab.split('/')]\n",
    "\n",
    "    assert vs == ps and set(ps) == {'/'}, (vocab, pinyin)\n",
    "    return [[v.strip(), p.strip()] for (v, p) in zip(vocab.split('/'), pinyin.split('/'))]\n",
    "\n",
    "def get_variants_str(vocab, pinyin, moe):\n",
    "    variants = get_variants(vocab, pinyin)\n",
    "    if not variants:\n",
    "        return ''\n",
    "    arr = []\n",
    "    for (trad, py) in variants:\n",
    "        m = [x for x in json.loads(moe.replace(\"'\", '\"')) if x[0] == trad]\n",
    "        assert len(m) <= 1\n",
    "        if m:\n",
    "            assert m[0][0] == trad\n",
    "            m = ' '.join(m[0][1])\n",
    "        else:\n",
    "            m = ''\n",
    "        arr.append({\n",
    "            'Traditional': trad,\n",
    "            'Simplified': to_simplified(trad),\n",
    "            'Pinyin': normalize_pinyin(py, trad),\n",
    "            'PinyinYB': py,\n",
    "            'MOE': m,\n",
    "        })\n",
    "    return json.dumps(arr, ensure_ascii=False)\n",
    "\n",
    "def fix_traditional(s):\n",
    "    # number suffixes for different pronunciations, +3 weird duplicate entries 空檔 道 來往\n",
    "    s = re.sub('[0-9]', '', s)\n",
    "    s = re.sub('／', '/', s)\n",
    "    assert re.match('^[\\u4E00-\\u9FFF/()]+$', s), (row, s)\n",
    "    return s\n",
    "\n",
    "PINYIN_MP = {\n",
    "    ('nǚér', '女兒'): \"nǚ'ér\",\n",
    "    ('wǎnān', '晚安'): \"wǎn'ān\",\n",
    "    ('zǎoān', '早安'): \"zǎo'ān\",\n",
    "    ('kěài', '可愛'): \"kě'ài\",\n",
    "    ('xiǎpéngyǒu', '小朋友'): 'xiǎopéngyǒu',\n",
    "    ('dáàn', '答案'): \"dá'àn\",\n",
    "    ('jú', '橘子'): 'júzi',\n",
    "    ('pèngchù', '碰觸/觸碰'): 'pèngchù/chùpèng',\n",
    "    ('wányèr', '玩意兒'): \"wányìr\",\n",
    "    ('qīněr', '親耳'): \"qīn'ěr\",\n",
    "    ('yāgēr', '壓根兒'): \"yāgēnr\",\n",
    "    ('yìdiǎn/yìdiǎndiǎn/yìdiǎr', '一點/一點點/一點兒'): 'yìdiǎn/yìdiǎndiǎn/yìdiǎnr',\n",
    "    ('xiáchí', '挾持'): 'xiéchí', #https://dict.revised.moe.edu.tw/dictView.jsp?ID=105985&word=%E6%8C%BE%E6%8C%81\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_pinyin(pinyin, hz):\n",
    "    if (pinyin, hz) == ('búzhìyú', '不至於/不致於'): return 'bùzhìyú'\n",
    "    if (pinyin, hz) == ('yíyìgūxíng', '一意孤行'): return 'yīyìgūxíng'\n",
    "\n",
    "    if '不' in hz and 'bú' in pinyin:\n",
    "        assert hz.count('不') == pinyin.count('bú') + pinyin.count('bù'), (pinyin, hz)\n",
    "        pinyin = pinyin.replace('bú', 'bù')\n",
    "\n",
    "    if '一' in hz and re.search('(yí|yì)', pinyin):\n",
    "        assert hz.count('一') == pinyin.count('yí') + pinyin.count('yì'), (pinyin, hz)\n",
    "        pinyin = pinyin.replace('yí', 'yī')\n",
    "        pinyin = pinyin.replace('yì', 'yī')\n",
    "\n",
    "    return pinyin\n",
    "\n",
    "def fix_pinyin(py, trad=''):\n",
    "    for x, y in ['ɑa', (' */ *', '/'), (r'\\s+', ' '), (' */$', ''), ('^/ *', '')]:\n",
    "        py = re.sub(x, y, py).strip()\n",
    "    if (py.replace(' ', ''), trad) in PINYIN_MP:\n",
    "        return PINYIN_MP[(py.replace(' ', ''), trad)]\n",
    "    # Pinyin spaces are not meaningul in TBCL lists, mostly just syllable spaces there.\n",
    "    # Remove to make more mergeable with TOCFL. Also no upper letters.\n",
    "    assert py == py.lower() and \"'\" not in py\n",
    "    merged = ''\n",
    "    for part in py.split():\n",
    "        if merged and merged[-1] not in '/()' and part[0] in 'aeoāáǎàēéěèōóǒò':\n",
    "            merged += \"'\"\n",
    "        merged += part\n",
    "    py = merged\n",
    "    assert re.match(\"^[a-zāáǎàēéěèīíǐìōóǒòūúǔùüǘǚǜ/()']+$\", py), (py, repr(py))\n",
    "    return py\n",
    "\n",
    "\n",
    "df = pd.read_excel('downloads/words.xlsx').rename(columns={\n",
    "    '序號': 'ID',\n",
    "    '詞語': 'Traditional',\n",
    "    '等別': 'Grade',\n",
    "    '級別': 'Level',\n",
    "    '情境': 'Context',\n",
    "    '書面字頻(每百萬字)': 'WritingFreq',\n",
    "    '口語字頻(每百萬字)': 'SpeakingFreq',\n",
    "    '簡編本系統號': 'MOE', # MOE dict IDs, https://dict.concised.moe.edu.tw/dictView.jsp?ID=.\n",
    "    '參考注音': 'Zhuyin',\n",
    "    '參考漢語拼音': 'PinyinYB'  # pinyin with tone change indication for 一 and 不\n",
    "})\n",
    "\n",
    "assert list(df.ID - 1) == list(df.index)\n",
    "df = df.drop(columns=['Grade', 'Zhuyin', 'Context'])\n",
    "\n",
    "df['Level'] = df.Level.str.extract('^第([1-7][*]?)級$')[0]\n",
    "assert sum(df.Level.isnull()) == 0\n",
    "\n",
    "df['glossary_key'] = (df.Level.str.slice(0, 1) + df.Traditional)\n",
    "glossary_df = glossary_df.fillna('')\n",
    "glossary_df['glossary_key'] = (glossary_df.Level.str.slice(0, 1) + glossary_df.Traditional)\n",
    "glossary_mp = glossary_df.assign(idx=glossary_df.index).groupby('glossary_key').idx.apply(list)\n",
    "\n",
    "df['Traditional'] = df.Traditional.map(fix_traditional)\n",
    "df.insert(2, 'Simplified', df.Traditional.map(to_simplified))\n",
    "df['PinyinYB'] = [fix_pinyin(row.PinyinYB, row.Traditional) for row in df.itertuples()]\n",
    "df['Pinyin'] = [normalize_pinyin(row.PinyinYB, row.Traditional) for row in df.itertuples()]\n",
    "df['Variants'] = [get_variants_str(row.Traditional, row.PinyinYB, row.MOE) for row in df.itertuples()]\n",
    "\n",
    "for row in df.itertuples():\n",
    "    variants = [v['Traditional'] for v in json.loads(row.Variants)] if row.Variants else [row.Traditional]\n",
    "    moe = json.loads(row.MOE.replace(\"'\", '\"'))\n",
    "    if row.Variants or row.MOE == '[]':\n",
    "        for v, ids in moe:\n",
    "            assert v in variants\n",
    "        df.loc[row.Index, 'MOE'] = ''\n",
    "    else:\n",
    "        assert len(moe) == 1 and moe[0][0] == row.Traditional\n",
    "        df.loc[row.Index, 'MOE'] = ' '.join(moe[0][1])\n",
    "\n",
    "# Join with vocab_df\n",
    "for col in ['POS', 'Meaning', 'Compounds', 'Examples']:\n",
    "    df[col] = ''\n",
    "    for row in df.itertuples():\n",
    "        text = [glossary_df.loc[i, col] for i in glossary_mp.get(row.glossary_key, [])]\n",
    "        text = [s.strip() for s in text if s.strip()]\n",
    "        assert ' / ' not in ''.join(text), text\n",
    "        if not text: continue\n",
    "        dedup = []\n",
    "        for s in text:\n",
    "            if s not in dedup: dedup.append(s)\n",
    "        text = ' / '.join(dedup)\n",
    "        if col == 'POS':\n",
    "            text = text.replace(' ', '')\n",
    "            text = text.replace('Phrase', 'Ph')\n",
    "        elif col == 'Compounds':\n",
    "            text = text.replace(';', '')\n",
    "            text = text.replace(' / ', '，').split('，')\n",
    "            dedup = []\n",
    "            for s in text:\n",
    "                if s not in dedup: dedup.append(s)\n",
    "            text = '，'.join(text)\n",
    "            if text: text += '。'\n",
    "        for x, y in [(' *[(] +', ' ('), (' +[)]', ')'), (' +/ +', ' / ')]:\n",
    "            text = re.sub(x, y, text).strip()\n",
    "        assert '\\n' not in text\n",
    "        df.loc[row.Index, col] = text.strip()\n",
    "\n",
    "print('Unjoined glossary vocab: %s' % ' '.join(set(glossary_df.glossary_key) - set(df.glossary_key)))\n",
    "df = df.drop(columns=['glossary_key'])\n",
    "\n",
    "df.to_csv('tbcl.csv', index=False)\n",
    "print('tbcl.csv: %d rows' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1de529-7e4d-4afb-a775-5417ced153ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbcl-expanded.csv: 14868 entries\n"
     ]
    }
   ],
   "source": [
    "# Generate version with variants expanded.\n",
    "\n",
    "expanded_rows = []\n",
    "for row in df.fillna('').to_dict(orient='records'):\n",
    "    variants = json.loads(row['Variants']) if row['Variants'] else [{}]\n",
    "    for variant in variants:\n",
    "        var = dict(row)\n",
    "        var.update(variant)\n",
    "        expanded_rows.append(var)\n",
    "\n",
    "expanded_df = pd.DataFrame(expanded_rows).drop(columns=['Variants'])\n",
    "expanded_df.to_csv('tbcl-expanded.csv', index=False)\n",
    "print('tbcl-expanded.csv: %d entries' % len(expanded_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ca61c0-a6e9-4c44-bf7e-189ac0b98741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 1121375 Nov  7 14:15 tbcl-pleco.txt\n"
     ]
    }
   ],
   "source": [
    "EAC1_TAG = '\\uEAC1\\uEC00\\uEC00\\uECCC\\uEC99'  # tag color, #00cc99 green\n",
    "EAC1_EX  = '\\uEAC1\\uEC00\\uEC05\\uECAA\\uECFF'  # examples, #05aaff blue\n",
    "EAC1_HL  = '\\uEAC1\\uEC00\\uEC00\\uECCC\\uECCC'  # term highlight in examples, teal\n",
    "\n",
    "with open('tbcl-pleco.txt', 'w') as fout:\n",
    "    last_header = ''\n",
    "    for row in pd.read_csv('tbcl.csv', dtype='str').fillna('').to_dict(orient='records'):\n",
    "        header = f\"//TBCL/Level {row['Level']}\"\n",
    "        if header != last_header:\n",
    "            last_header = header\n",
    "            fout.write(header + '\\n')\n",
    "\n",
    "        variants = json.loads(row['Variants']) if row['Variants'] else [{}]\n",
    "        for variant in variants:\n",
    "            var = dict(row)\n",
    "            var.update(variant)\n",
    "            defn = ' '.join([\n",
    "                f\"{row['Traditional']} [{row['Pinyin']}]\\uEAB1\" if row['Variants'] else '',\n",
    "                f\"({row['POS']})\" if row.get('POS') else '',\n",
    "                f\"{row['Meaning']}\" if row.get('Meaning') else '',\n",
    "                f\"{EAC1_TAG}[TBCL{row['Level']}]\\uEAC2\",\n",
    "            ])\n",
    "            defn = re.sub(r'\\s+', ' ', defn).replace('\\uEAB1 ', '\\uEAB1').strip()\n",
    "            # Compounds and examples in light blue on separate lines\n",
    "            for ex in [var['Compounds'], var['Examples']]:\n",
    "                if not ex: continue\n",
    "                defn += (\n",
    "                    f'\\uEAB1{EAC1_EX}' +\n",
    "                    ex.replace(' / ', '\\uEAB1').replace(\n",
    "                        var['Traditional'],\n",
    "                        f\"\\uEAC2{EAC1_HL}{var['Traditional']}\\uEAC2{EAC1_EX}\"\n",
    "                    ) +\n",
    "                    '\\uEAC2'\n",
    "                )\n",
    "            key = f\"{var['Simplified']}[{var['Traditional']}]\\t{var['Pinyin']}\"\n",
    "            fout.write(f'{key}\\t{defn}\\n')\n",
    "\n",
    "!ls -l tbcl-pleco.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf03e3-7b61-483b-a1e0-49d072e4c3e6",
   "metadata": {},
   "source": [
    "## Convert other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88b5e6e-fdbf-4a0e-b41d-febf6e953c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars.csv: 3100 rows\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('downloads/chars.xlsx').rename(columns={\n",
    "    '序號': 'ID',\n",
    "    '漢字': 'Traditional',\n",
    "    '等別': 'Grade',\n",
    "    '級別': 'Level',\n",
    "    '情境': 'Context',\n",
    "    '書面字頻（每百萬字）': 'WritingFreq',\n",
    "    '口語字頻（每百萬字）': 'SpeakingFreq',\n",
    "})\n",
    "\n",
    "assert list(df.ID - 1) == list(df.index)\n",
    "df = df.drop(columns=['Grade'])\n",
    "\n",
    "df['Level'] = df.Level.str.extract('^第([1-7][*]?)級$')[0]\n",
    "assert sum(df.Level.isnull()) == 0\n",
    "\n",
    "df['Traditional'] = df.Traditional.map(fix_traditional)\n",
    "df.to_csv('chars.csv', index=False)\n",
    "print('chars.csv: %d rows' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c6d60d-52dc-4de6-bde3-833404500dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars-expanded.csv: 3133 rows\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for row in df.to_dict(orient='records'):\n",
    "    for ch in row['Traditional'].split('/'):\n",
    "        row['char'] = ch\n",
    "        rows.append(dict(row))\n",
    "\n",
    "expanded_df = pd.DataFrame(rows)[['char'] + list(df.columns)]\n",
    "expanded_df.to_csv('chars-expanded.csv', index=False)\n",
    "print('chars-expanded.csv: %d rows' % len(expanded_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6551c31f-f48a-4e2f-ae79-e38f5bf78775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grammar.csv: 496 rows\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('downloads/grammar.xlsx').rename(columns={\n",
    "    '序號': 'ID',\n",
    "    '語法點': 'Grammar',\n",
    "    '等別': 'Grade',\n",
    "    '級別': 'Level',\n",
    "    '例句': 'Example',\n",
    "})\n",
    "\n",
    "assert list(df.ID - 1) == list(df.index)\n",
    "df = df.drop(columns=['Grade'])\n",
    "\n",
    "df['Level'] = df.Level.str.extract('^第([1-7][*]?)級$')[0]\n",
    "assert sum(df.Level.isnull()) == 0\n",
    "\n",
    "df.to_csv('grammar.csv', index=False)\n",
    "print('grammar.csv: %d rows' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d4821a7-b877-4413-8774-5cb2b3964920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affixes.csv: 73 rows\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('downloads/affixes.xlsx').rename(columns={\n",
    "    '序號': 'ID',\n",
    "    '類詞綴': 'Affix',\n",
    "    '語法點': 'Grammar',\n",
    "    '級別': 'Level',\n",
    "    '說明': 'Explanation',\n",
    "    '相關詞彙': 'Words',\n",
    "})\n",
    "assert list(df.ID - 1) == list(df.index)\n",
    "\n",
    "df['Level'] = df.Level.str.extract('^第([1-7][*]?)級$')[0]\n",
    "assert sum(df.Level.isnull()) == 0\n",
    "\n",
    "df.to_csv('affixes.csv', index=False)\n",
    "print('affixes.csv: %d rows' % len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde2681b-d30d-49b8-a902-78f2209a99be",
   "metadata": {},
   "source": [
    "## Readings check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9458efc4-51ad-4022-8513-61208da0ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tbcl.csv', dtype='str').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3d5db96-c576-4406-a032-c14abd57e367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1533', '噢', '噢', '4', '80', '19', '44379', 'yǔ'] :\t 噢 yǔ vs. ['ō']\n",
      "['1572', '阿嬤', '阿嬷', '4', '41', '301', '', 'āma'] :\t 阿嬤 āma vs. ['ēmo', 'ēmó', 'ēmā', 'àmo', 'àmó', 'àmā', 'āmo', 'āmó', 'āmā']\n",
      "['2889', '尺寸', '尺寸', '5', '13', '13', '31455', 'chícun'] :\t 尺寸 chícun vs. ['chǐcun', 'chǐcùn', 'chěcun', 'chěcùn']\n",
      "['3331', '古蹟', '古迹', '5', '7', '26', '', 'gǔjī'] :\t 古蹟 gǔjī vs. ['gǔjì']\n",
      "['4063', '奇蹟', '奇迹', '5', '31', '24', '24507', 'qíjī'] :\t 奇蹟 qíjī vs. ['jījì', 'qíjì']\n",
      "['5329', '磅', '磅', '6', '12', '3', '2839 1146', 'pāng'] :\t 磅 pāng vs. ['bàng', 'páng']\n",
      "['7155', '摟', '搂', '6', '9', '1', '13652 13656 13677', 'lóu'] :\t 摟 lóu vs. ['lǒu', 'lou', 'lōu']\n",
      "['7486', '舖', '铺', '6', '32', '26', '', 'pū'] :\t 舖 pū vs. ['pù']\n",
      "['7542', '齊', '齐', '6', '33', '22', '21691 24545 36690', 'zī'] :\t 齊 zī vs. ['qí']\n",
      "['7946', '事蹟', '事迹', '6', '15', '5', '33653', 'shìjī'] :\t 事蹟 shìjī vs. ['shìjì', 'shijì']\n",
      "['8358', '蜿蜒', '蜿蜒', '6', '8', '7', '43635', 'wǎnyán'] :\t 蜿蜒 wǎnyán vs. ['wānyán', 'wānyan']\n",
      "['8440', '無妨', '无妨', '6', '7', '1', '42716', 'wúfāng'] :\t 無妨 wúfāng vs. ['wúfáng', 'mófáng']\n",
      "['8894', '一心一意', '一心一意', '6', '7', '3', '40144', 'yìxīnyīyì'] :\t 一心一意 yīxīnyīyī vs. ['yixīnyiyi', 'yixīnyiyì', 'yixīnyāoyi', 'yixīnyāoyì', 'yixīnyīyi', 'yixīnyīyì', 'yixinyiyi', 'yixinyiyì', 'yixinyāoyi', 'yixinyāoyì']\n",
      "['9256', '忠告', '忠告', '6', '10', '2', '31207', 'zhōnggù'] :\t 忠告 zhōnggù vs. ['zhōnggào', 'zhōnggao']\n",
      "['9386', '縱', '纵', '6', '19', '3', '37678 37736', 'zōng'] :\t 縱 zōng vs. ['zòng']\n",
      "['9387', '縱橫', '纵横', '6', '10', '5', '37682', 'zōnghéng'] :\t 縱橫 zōnghéng vs. ['zònghèng', 'zònghéng']\n",
      "['11561', '牢靠', '牢靠', '7', '2', '1', '13430', 'láokao'] :\t 牢靠 láokao vs. ['láokào']\n",
      "['11583', '怔', '怔', '7', '4', '1', '13923 30226', 'lèng'] :\t 怔 lèng vs. ['zhèng', 'zhēng']\n",
      "['12041', '澎湃', '澎湃', '7', '6', '3', '2890', 'pēngpài'] :\t 澎湃 pēngpài vs. ['péngpài']\n",
      "['12098', '平反', '平反', '7', '6', '1', '3293', 'píngfān'] :\t 平反 píngfān vs. ['píngfǎn']\n",
      "['12134', '舖陳', '铺陈', '7', '6', '1', '', 'pūchén'] :\t 舖陳 pūchén vs. ['pùchén']\n",
      "['12136', '舖路', '铺路', '7', '4', '2', '', 'pūlù'] :\t 舖路 pūlù vs. ['pùlu', 'pùlù']\n",
      "['12138', '舖設', '铺设', '7', '5', '8', '', 'pūshè'] :\t 舖設 pūshè vs. ['pùshè', 'pùshe']\n",
      "['12667', '視網膜', '视网膜', '7', '5', '3', '', 'shìwǎngmò'] :\t 視網膜 shìwǎngmò vs. ['shìwǎngmó']\n",
      "['12886', '探頭', '探头', '7', '6', '1', '10547', 'tāntóu'] :\t 探頭 tāntóu vs. ['tàntou', 'tàntóu']\n",
      "['14109', '震懾', '震慑', '7', '4', '2', '30078', 'zhènzhé'] :\t 震懾 zhènzhé vs. ['zhènshè']\n",
      "['14244', '皺眉頭', '皱眉头', '7', '9', '1', '', 'zhòuméi'] :\t 皺眉頭 zhòuméi vs. ['zhòuméitou', 'zhòuméitóu']\n",
      "['14244', '皺眉', '皱眉', '7', '9', '1', '', 'zhòuméitóu'] :\t 皺眉 zhòuméitóu vs. ['zhòuméi']\n",
      "['14326', '自白', '自白', '7', '3', '0', '36768', 'zìbó'] :\t 自白 zìbó vs. ['zibai', 'zibái', 'zìbai', 'zìbái']\n"
     ]
    }
   ],
   "source": [
    "# Check readings\n",
    "if os.path.exists('../cedict/syllables.csv'):\n",
    "    readings_mp = {}  # {'一': set(['yì','yí'])}\n",
    "    syll_df = pd.read_csv('../cedict/syllables.csv', dtype='str').fillna('')\n",
    "    for row in syll_df.itertuples():\n",
    "        readings_mp.setdefault(row.Traditional, set()).add(row.Pinyin.lower())\n",
    "        readings_mp.setdefault(row.Simplified, set()).add(row.Pinyin.lower())\n",
    "    readings_mp = {x: set([y.strip().lower() for y in readings_mp[x] if y.strip()]) for x in readings_mp}\n",
    "    readings_mp['不'] = set(['bù'])\n",
    "\n",
    "    def gen_readings(trad):\n",
    "        if trad == '':\n",
    "            yield ''\n",
    "        elif trad[0] not in readings_mp or ord(trad[0]) < 0x3E00:\n",
    "            yield from gen_readings(trad[1:])\n",
    "        else:\n",
    "            for x in readings_mp[trad[0]]:\n",
    "                for y in gen_readings(trad[1:]):\n",
    "                    yield x.lower() + (\"'\" if y and y[0] in 'aāáǎàeēéěèoōóǒò' else '') + y\n",
    "\n",
    "    for row in pd.read_csv('tbcl-expanded.csv', dtype='str').fillna('').itertuples():\n",
    "        trad, pinyin = row.Traditional,row.Pinyin\n",
    "        readings = list(gen_readings(trad))\n",
    "        if re.sub('', '', pinyin) not in readings:\n",
    "            print(list(row._asdict().values())[1:9], ':\\t', trad, pinyin, 'vs.', readings[:min(10, len(readings))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a3f32-3ccc-48f6-9a0a-2371d9b1763c",
   "metadata": {},
   "source": [
    "## Merge with CEDICT and generate anki deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41795481-ab01-4272-9439-f75802e697bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNTONE_MP = {\n",
    "    'a': 'a', 'ā': 'a', 'á': 'a', 'ǎ': 'a', 'à': 'a',\n",
    "    'e': 'e', 'ē': 'e', 'é': 'e', 'ě': 'e', 'è': 'e',\n",
    "    'o': 'o', 'ō': 'o', 'ó': 'o', 'ǒ': 'o', 'ò': 'o',\n",
    "    'i': 'i', 'ī': 'i', 'í': 'i', 'ǐ': 'i', 'ì': 'i',\n",
    "    'u': 'u', 'ū': 'u', 'ú': 'u', 'ǔ': 'u', 'ù': 'u',\n",
    "    'ü': 'ü', 'ǖ': 'ü', 'ǘ': 'ü', 'ǚ': 'ü', 'ǜ': 'ü'\n",
    "}\n",
    "\n",
    "# Check if pinyin from data (py1) matches cedict's (py2)\n",
    "# Optionally matching untoned vowels with tones if untone==True.\n",
    "def pinyin_matches(py1, py2, hz='', untone=False, yi=False, bu=False):\n",
    "    py1 = py1.lower()\n",
    "    py2 = py2.lower()\n",
    "    i, j = 0, 0\n",
    "    while i < len(py1) or j < len(py2):\n",
    "        a = ''\n",
    "        if i < len(py1):\n",
    "            a = py1[i]\n",
    "            if a in \"-',/() \":\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "        b = ''\n",
    "        if j < len(py2):\n",
    "            b = py2[j]\n",
    "            if b in \"-',/() \":\n",
    "                j += 1\n",
    "                continue\n",
    "\n",
    "        match = (a == b)\n",
    "        match |= untone and (UNTONE_MP.get(a, a) == b or a == UNTONE_MP.get(b, b))\n",
    "        if i > 0 and j > 0:\n",
    "            match |= yi and py1[i-1:i+1] in ['yí', 'yì'] and py2[j-1:j+1] == 'yī' and '一' in hz\n",
    "            match |= bu and py1[i-1:i+1] == 'bú' and py2[j-1:j+1] == 'bù' and '不' in hz\n",
    "\n",
    "        if match:\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return i == len(py1) and j == len(py2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b57f33fc-8e25-4d6e-8405-57fd35745d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambigous simplified: {'ID': '85', 'Traditional': '妳', 'Simplified': '你', 'Level': '1', 'WritingFreq': '463', 'SpeakingFreq': '1653', 'MOE': '12580', 'PinyinYB': 'nǐ', 'Pinyin': 'nǐ', 'Variants': '', 'POS': 'N', 'Meaning': 'you (female)', 'Compounds': '', 'Examples': '妳好，我是妳的同學。'} ce {'奶', '你'} cc 妳\n",
      "Ambigous simplified: {'ID': '853', 'Traditional': '乾', 'Simplified': '干', 'Level': '3', 'WritingFreq': '50', 'SpeakingFreq': '99', 'MOE': '16341 25228', 'PinyinYB': 'gān', 'Pinyin': 'gān', 'Variants': '', 'POS': 'Vs/N', 'Meaning': 'dry / dried food', 'Compounds': '魚乾，肉乾，葡萄乾。', 'Examples': '今天早上洗的衣服，下午就乾了。 / 最近的天氣很乾，都沒有下雨。 / 我喜歡吃水果乾。'} ce {'干', '乾'} cc 干\n",
      "Simplified diff: {'ID': '1482', 'Traditional': '牠', 'Simplified': '它', 'Level': '4', 'WritingFreq': '343', 'SpeakingFreq': '659', 'MOE': '9925', 'PinyinYB': 'tā', 'Pinyin': 'tā', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'牠'} cc 牠\n",
      "Simplified diff: {'ID': '3615', 'Traditional': '藉口', 'Simplified': '借口', 'Level': '5', 'WritingFreq': '32', 'SpeakingFreq': '10', 'MOE': '22281', 'PinyinYB': 'jièkǒu', 'Pinyin': 'jièkǒu', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'藉口'} cc 借口\n",
      "Simplified diff: {'ID': '4411', 'Traditional': '蒐集', 'Simplified': '搜集', 'Level': '5', 'WritingFreq': '30', 'SpeakingFreq': '19', 'MOE': '38841', 'PinyinYB': 'sōují', 'Pinyin': 'sōují', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'蒐集'} cc 搜集\n",
      "Ambigous simplified: {'ID': '4690', 'Traditional': '閒', 'Simplified': '闲', 'Level': '5', 'WritingFreq': '14', 'SpeakingFreq': '10', 'MOE': '27364', 'PinyinYB': 'xián', 'Pinyin': 'xián', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'閒', '闲'} cc 闲\n",
      "Ambigous simplified: {'ID': '4962', 'Traditional': '於', 'Simplified': '于', 'Level': '5', 'WritingFreq': '1026', 'SpeakingFreq': '269', 'MOE': '42632 44183', 'PinyinYB': 'yú', 'Pinyin': 'yú', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'于', '於'} cc 于\n",
      "Ambigous simplified: {'ID': '4963', 'Traditional': '餘', 'Simplified': '余', 'Level': '5', 'WritingFreq': '12', 'SpeakingFreq': '13', 'MOE': '44157', 'PinyinYB': 'yú', 'Pinyin': 'yú', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'馀', '余'} cc 余\n",
      "Simplified diff: {'ID': '5763', 'Traditional': '大夥', 'Simplified': '大伙', 'Level': '6', 'WritingFreq': '9', 'SpeakingFreq': '2', 'MOE': '', 'PinyinYB': 'dàhuǒ', 'Pinyin': 'dàhuǒ', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'大夥'} cc 大伙\n",
      "Ambigous simplified: {'ID': '6512', 'Traditional': '夥', 'Simplified': '伙', 'Level': '6', 'WritingFreq': '9', 'SpeakingFreq': '2', 'MOE': '20357', 'PinyinYB': 'huǒ', 'Pinyin': 'huǒ', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'伙', '夥'} cc 伙\n",
      "Ambigous simplified: {'ID': '6754', 'Traditional': '藉由', 'Simplified': '借由', 'Level': '6', 'WritingFreq': '53', 'SpeakingFreq': '91', 'MOE': '45308', 'PinyinYB': 'jièyóu', 'Pinyin': 'jièyóu', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'藉由', '借由'} cc 借由\n",
      "Simplified diff: {'ID': '7462', 'Traditional': '憑藉', 'Simplified': '凭借', 'Level': '6', 'WritingFreq': '11', 'SpeakingFreq': '7', 'MOE': '3407', 'PinyinYB': 'píngjiè', 'Pinyin': 'píngjiè', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'凭藉'} cc 凭借\n",
      "Simplified diff: {'ID': '9046', 'Traditional': '原著', 'Simplified': '原着', 'Level': '6', 'WritingFreq': '12', 'SpeakingFreq': '1', 'MOE': '44779', 'PinyinYB': 'yuánzhù', 'Pinyin': 'yuánzhù', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'原著'} cc 原着\n",
      "Ambigous simplified: {'ID': '9281', 'Traditional': '著', 'Simplified': '着', 'Level': '6', 'WritingFreq': '4017', 'SpeakingFreq': '1760', 'MOE': '29560 29632 29651 30743 30817', 'PinyinYB': 'zhù', 'Pinyin': 'zhù', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'着', '著'} cc 着\n",
      "Ambigous simplified: {'ID': '9347', 'Traditional': '著', 'Simplified': '着', 'Level': '6', 'WritingFreq': '4017', 'SpeakingFreq': '1760', 'MOE': '29560 29632 29651 30743 30817', 'PinyinYB': 'zhuó', 'Pinyin': 'zhuó', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'着', '著'} cc 着\n",
      "Simplified diff: {'ID': '9372', 'Traditional': '諮商', 'Simplified': '咨商', 'Level': '6', 'WritingFreq': '24', 'SpeakingFreq': '4', 'MOE': '36665', 'PinyinYB': 'zīshāng', 'Pinyin': 'zīshāng', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'谘商'} cc 咨商\n",
      "Simplified diff: {'ID': '9375', 'Traditional': '諮詢', 'Simplified': '咨询', 'Level': '6', 'WritingFreq': '20', 'SpeakingFreq': '7', 'MOE': '36664', 'PinyinYB': 'zīxún', 'Pinyin': 'zīxún', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'谘询'} cc 咨询\n",
      "Ambigous simplified: {'ID': '9756', 'Traditional': '參', 'Simplified': '参', 'Level': '7', 'WritingFreq': '5', 'SpeakingFreq': '2', 'MOE': '34675 38101 38188 38923', 'PinyinYB': 'cān', 'Pinyin': 'cān', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'叁', '参'} cc 参\n",
      "Simplified diff: {'ID': '10202', 'Traditional': '牴觸', 'Simplified': '抵触', 'Level': '7', 'WritingFreq': '3', 'SpeakingFreq': '1', 'MOE': '8390', 'PinyinYB': 'dǐchù', 'Pinyin': 'dǐchù', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'牴触'} cc 抵触\n",
      "Simplified diff: {'ID': '11369', 'Traditional': '鉅', 'Simplified': '巨', 'Level': '7', 'WritingFreq': '5', 'SpeakingFreq': '3', 'MOE': '23993', 'PinyinYB': 'jù', 'Pinyin': 'jù', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'钜'} cc 巨\n",
      "Simplified diff: {'ID': '11373', 'Traditional': '鉅額', 'Simplified': '巨额', 'Level': '7', 'WritingFreq': '3', 'SpeakingFreq': '1', 'MOE': '24000', 'PinyinYB': \"jù'é\", 'Pinyin': \"jù'é\", 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'钜额'} cc 巨额\n",
      "Ambigous simplified: {'ID': '12193', 'Traditional': '乾', 'Simplified': '干', 'Level': '7', 'WritingFreq': '50', 'SpeakingFreq': '99', 'MOE': '16341 25228', 'PinyinYB': 'qián', 'Pinyin': 'qián', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'干', '乾'} cc 干\n",
      "Simplified diff: {'ID': '13054', 'Traditional': '土著', 'Simplified': '土着', 'Level': '7', 'WritingFreq': '5', 'SpeakingFreq': '1', 'MOE': '11536', 'PinyinYB': 'tǔzhù', 'Pinyin': 'tǔzhù', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'土著'} cc 土着\n",
      "Ambigous simplified: {'ID': '13571', 'Traditional': '薰', 'Simplified': '薰', 'Level': '7', 'WritingFreq': '4', 'SpeakingFreq': '8', 'MOE': '28690', 'PinyinYB': 'xūn', 'Pinyin': 'xūn', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'薰', '熏'} cc 薰\n",
      "Simplified diff: {'ID': '13581', 'Traditional': '薰陶', 'Simplified': '薰陶', 'Level': '7', 'WritingFreq': '4', 'SpeakingFreq': '5', 'MOE': '28692', 'PinyinYB': 'xūntáo', 'Pinyin': 'xūntáo', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'熏陶'} cc 薰陶\n",
      "Ambigous simplified: {'ID': '14061', 'Traditional': '著', 'Simplified': '着', 'Level': '7', 'WritingFreq': '4017', 'SpeakingFreq': '1760', 'MOE': '29560 29632 29651 30743 30817', 'PinyinYB': 'zháo', 'Pinyin': 'zháo', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'着', '著'} cc 着\n",
      "Simplified diff: {'ID': '14321', 'Traditional': '卓著', 'Simplified': '卓着', 'Level': '7', 'WritingFreq': '4', 'SpeakingFreq': '1', 'MOE': '30807', 'PinyinYB': 'zhuózhù', 'Pinyin': 'zhuózhù', 'Variants': '', 'POS': '', 'Meaning': '', 'Compounds': '', 'Examples': ''} ce {'卓著'} cc 卓着\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('tbcl.csv', dtype='str').fillna('')\n",
    "cedict_df = pd.read_csv('../cedict/cedict.csv')\n",
    "cedict_idx_mp = cedict_df.assign(idx=cedict_df.index).groupby('Traditional').idx.apply(list)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for row in df.fillna('').to_dict(orient='records'):\n",
    "    pinyin_set = set([row['Pinyin']])\n",
    "    matches = cedict_idx_mp.get(row['Traditional'], [])\n",
    "    if len(matches) == 0 and row['Variants']:\n",
    "        variants = json.loads(row['Variants']) if row['Variants'] else [{}]\n",
    "        for variant in variants:\n",
    "            matches.extend(cedict_idx_mp.get(variant['Traditional'], []))\n",
    "            pinyin_set.add(variant['Pinyin'])\n",
    "\n",
    "    matches = list(sorted(set(matches)))\n",
    "\n",
    "    flag = ''\n",
    "    if len(matches) != 0:\n",
    "        # Prioritize pronunciation matches, downpriorize names and variants\n",
    "        # TODO: match based on taiwanese pronunciation\n",
    "        if len(matches) > 1:\n",
    "            matches.sort(key=lambda i: (\n",
    "                -int(any(pinyin_matches(py, cedict_df.Pinyin[i], untone=False) for py in pinyin_set))\n",
    "                -int(any(pinyin_matches(py, cedict_df.Pinyin[i], untone=True) for py in pinyin_set))\n",
    "                +10*int(re.match('^variant', cedict_df.Definitions[i]) is not None)\n",
    "                +100*int(cedict_df.Pinyin[i][0].isupper())\n",
    "            ))\n",
    "\n",
    "        ce_simp = set([cedict_df.Simplified[i] for i in matches])\n",
    "        cc_simp = opencc_tw2s.convert(row['Traditional'])\n",
    "        if not row['Variants'] and ce_simp:\n",
    "            if row['Simplified'] not in ce_simp:\n",
    "                print('Simplified diff:', row, 'ce', ce_simp, 'cc', cc_simp)\n",
    "            if len(ce_simp) > 1:\n",
    "                print('Ambigous simplified:', row, 'ce', ce_simp, 'cc', cc_simp)\n",
    "\n",
    "        defs = []\n",
    "        for i in matches:\n",
    "            py1 = list(pinyin_set)[0] if len(pinyin_set) == 1 else ''\n",
    "            defn = cedict_df.Definitions[i]\n",
    "            defn = re.sub(r'/CL:個\\|个\\[ge4\\](|/.*)$', r'\\1', defn)  # uninformative\n",
    "            if row['Variants']:\n",
    "                defn = '%s [%s] %s' % (cedict_df.Traditional[i], cedict_df.Pinyin[i], defn)\n",
    "            elif not pinyin_matches(py1, cedict_df.Pinyin[i], untone=False):\n",
    "                defn = '[%s] %s' % (cedict_df.Pinyin[i], defn)\n",
    "            defs.append(defn)\n",
    "\n",
    "        if not row['Meaning']:\n",
    "            row['Meaning'] = '<br> '.join(defs)\n",
    "\n",
    "    #row['Flag'] = flag\n",
    "    rows.append(row)\n",
    "\n",
    "merged_df = pd.DataFrame(rows)\n",
    "merged_df.to_csv('tbcl-cedict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3994829-978e-4d2c-9779-71449ae11558",
   "metadata": {},
   "source": [
    "*Taiwan TBCL wordlist (Traditional)*\n",
    "\n",
    "TBCL (Taiwan Benchmarks for the Chinese Language) wordlist, 14425 words over 7 levels. Parsed from official excel sheets from [TBCL](https://coct.naer.edu.tw/TBCL/) website, including definitions/examples for about 1500 lower level words that they provide. CC-CEDICT definitions for the rest.\n",
    "\n",
    "Pinyin normalized to not indicate tone changes for 一 and 不 for ease of joining with other data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97300889-3880-45ed-abeb-e228f1f81460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 16947510 Nov  7 14:15 tbcl.apkg\n"
     ]
    }
   ],
   "source": [
    "import genanki, shutil\n",
    "\n",
    "df = merged_df.copy().fillna('')\n",
    "\n",
    "!mkdir -p data/media\n",
    "!cp -f ../downloads/fonts/MoeStandardKai.ttf data/media/_MoeStandardKai.ttf\n",
    "\n",
    "cols = ['ID', 'Traditional', 'Simplified', 'Pinyin', 'Level',\n",
    "        'POS', 'Meaning', 'Compounds', 'Examples', 'Variants']\n",
    "\n",
    "model = genanki.Model(\n",
    "    1698579990,\n",
    "    'TBCL',\n",
    "    fields=[{'name': c} for c in cols],\n",
    "    templates=[{\n",
    "        'name': 'TBCL',\n",
    "        'qfmt': open('../dangdai/dangdai-qfmt.html').read().replace('{{ID}}', 'TBCL L{{Level}}'),\n",
    "        # TODO fix template\n",
    "        'afmt': '''{{FrontSide}}\n",
    "<hr id=answer>\n",
    "<div lang=\"en\"><span id=\"ddzw-pinyin\">{{Pinyin}}</span></div><br>\n",
    "<div lang=\"en\">{{#POS}}({{POS}}) {{/POS}}{{Meaning}}</div><br>\n",
    "<div>{{#Compounds}}{{Compounds}}<br>{{/Compounds}}{{Examples}}</div><br>\n",
    "''' + re.sub('^.*<script>', '<script>', open('../dangdai/dangdai-afmt.html').read(), flags=re.M).replace(\n",
    "            'if (pinyinEl && hanziEl)',\n",
    "            'if (pinyinEl && hanziEl {{#Variants}}&& false{{/Variants}})'),\n",
    "    }],\n",
    "    css=open('../dangdai/dangdai.css').read(),\n",
    ")\n",
    "\n",
    "deck = genanki.Deck(1698579991, name='tbcl')\n",
    "\n",
    "for row in df.reset_index().to_dict(orient='records'):\n",
    "    note = genanki.Note(\n",
    "        model=model,\n",
    "        fields=[row[c] for c in cols],\n",
    "        guid=genanki.guid_for('tbcl', row['ID']),\n",
    "        tags=['L%s' % row['Level'][0]],\n",
    "    )\n",
    "    deck.add_note(note)\n",
    "\n",
    "!rm -f tbcl.apkg\n",
    "genanki.Package(deck, media_files=glob.glob('data/media/*')).write_to_file('tbcl.apkg')\n",
    "!ls -l tbcl.apkg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
