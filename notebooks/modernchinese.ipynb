{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2efcc08e-e383-47f9-a755-ad123231c3fc",
   "metadata": {},
   "source": [
    "# Modern Chinese (時代華語) vocabulary deck\n",
    "\n",
    "Anki flashcards deck for the vocabulary from *Modern Chinese (時代華語)*, a recent (2019-2021) Mandarin textbook series by Tamkang University Chinese Language Center et al from Taiwan. It's a popular textbook in many language schools in Taiwan and one of TOCFL's recommended textbooks. This is a traditional Chinese textbook and biased towards taiwanese Mandarin.\n",
    "\n",
    "Terms are from .pptx slides from the book's website: [https://sites.google.com/clc.tku.edu.tw/modernchinese-official/](https://sites.google.com/clc.tku.edu.tw/modernchinese-official/)\n",
    "\n",
    "In total the series now has 7 books with around 8000 terms. But as the slides are only available for the first four books currently, that's only what this deck covers. There are some differences because of errors/omissions in the slides.\n",
    "\n",
    "`ID`: a unique sortable term key e.g. `B1L16-3-1` = book 1, lesson 16, vocab part 3, term 1. You can use it to filter terms down to particular lessons you are need. Terms inside a section are numbered merely after the slides and would usually different from the books, doubly so because the books skip numbering some terms.\n",
    "\n",
    "`POS`: part of speech.\n",
    "\n",
    "`Audio`: neural TTS generated audio with a taiwanese config, but might still mispronounce some terms if there are multiple readings of the same hanzi. The book's website actually also provides [recorded audios](https://sites.google.com/clc.tku.edu.tw/modernchinese-official/%E9%9F%B3%E6%AA%94), but for whole vocab sections rather than split up by term, so it wouldn't be easy to add them to the deck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f91709-2d9e-4da4-bd45-12f509dc06dc",
   "metadata": {},
   "source": [
    "TODO: perhaps transcribe with whisper and use some anki subtitles/srt tools to load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7efa796-7012-4bd4-afcd-0573386a3fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q python-pptx genanki opencc\n",
    "\n",
    "import glob\n",
    "import os, os.path\n",
    "import re\n",
    "import pandas as pd\n",
    "import genanki\n",
    "import json\n",
    "from pptx import Presentation\n",
    "from opencc import OpenCC\n",
    "\n",
    "opencc_tw2s = OpenCC('tw2s')\n",
    "\n",
    "# Media files for the deck, point to Anki's collection.media dir\n",
    "MEDIA_DIR = '/home/ivan/zhongwen/Anki2/ivan/collection.media'\n",
    "TTS_MP3_PATTERN = f'{MEDIA_DIR}/modernchinese-tts-%s.mp3'\n",
    "\n",
    "# Modify to point to your downloaded copy of the slides if you need to rerun slides parser.\n",
    "PPTX_PATHS = {}\n",
    "for d in sorted(glob.glob('/home/ivan/zhongwen/data/modernchinese/B?L??')):\n",
    "    pp = glob.glob(d + '/*.pptx')\n",
    "    pp = [s for s in pp if not re.match('.*(_0617.pptx|短文速讀|學習單1|學習單2附件).*', s)]\n",
    "    assert len(pp) == 1\n",
    "    PPTX_PATHS[os.path.basename(d)] = pp[0]\n",
    "\n",
    "# Download ex.\n",
    "# url=\"https://sites.google.com/clc.tku.edu.tw/modernchinese-official/%E7%AC%AC%E4%B8%80%E5%86%8A/b1-l1\"\n",
    "# for driveid in $(curl \"$url\" |\n",
    "#                  egrep -o '<iframe[^>]*drive.google.com[^>]*preview[^>]*>' |\n",
    "#                  sed -Ee 's|.*https://drive.google.com/file/d/([^/]+)/preview.*|\\1|'); do\n",
    "#   rclone backend copyid drive: \"$driveid\" ./\n",
    "# done\n",
    "#\n",
    "# rclone via docker/podman:\n",
    "# podman run -v ~/.config/rclone:/config/rclone:rw -v \"$PWD:/pwd:rw\" docker.io/rclone/rclone backend copyid drive: \"$driveid\" /pwd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e91f0d-06a7-4a2c-81bc-02cbf6ff74d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore slides layout\n",
    "\n",
    "if 0:\n",
    "    rows = []\n",
    "    for book in ['B1', 'B2', 'B3', 'B4']:\n",
    "        for lesson, filepath in PPTX_PATHS.items():\n",
    "            if not lesson.startswith(book): continue\n",
    "            prs = Presentation(filepath)\n",
    "            for i, slide in enumerate(prs.slides):\n",
    "                rows.append({'Book': book, 'Lesson': lesson, 'Page': i+1, 'Layout': slide.slide_layout.name})\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(df.groupby('Book').Layout.value_counts())\n",
    "\n",
    "def explore(lesson, page=None):\n",
    "    book = lesson[:2]\n",
    "    filepath = PPTX_PATHS[lesson]\n",
    "    prs = Presentation(filepath)\n",
    "    res = []\n",
    "    for slide_i, slide in enumerate(prs.slides):\n",
    "        if page and slide_i+1 != page: continue\n",
    "        paragraphs = []\n",
    "        for shape in slide.shapes:\n",
    "            if not shape.has_text_frame: continue\n",
    "            for paragraph in shape.text_frame.paragraphs:\n",
    "                text = ''.join(run.text for run in paragraph.runs).strip()\n",
    "                if not text: continue\n",
    "                pidx = shape.placeholder_format.idx if shape.is_placeholder else None\n",
    "                #if (book, slide.slide_layout.name, pidx) in placeholders_mapping: continue\n",
    "                paragraphs.append((text, pidx))\n",
    "        if len(paragraphs) == 0: continue\n",
    "        res.append({'page': slide_i+1, 'layout': slide.slide_layout.name, 'paragraphs': paragraphs})\n",
    "\n",
    "    return res\n",
    "\n",
    "#explore('B4L02', 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ec13a5-ed7b-4d77-91a6-51362cc128dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from slides\n",
    "\n",
    "# book/lesson, layout, placeholder idx -> field\n",
    "PLACEHOLDER_MAP = {\n",
    "    ('B1L00', ' 生詞', 10): 'Traditional',\n",
    "    ('B1L00', ' 生詞', 11): 'Pinyin',\n",
    "    ('B1L00', ' 生詞', 12): 'POS',\n",
    "    ('B1L00', ' 生詞', 13): 'Meaning',\n",
    "    ('B1', ' 生詞', 1): 'Traditional',\n",
    "    ('B1', ' 生詞', 2): 'Pinyin',\n",
    "    ('B1', ' 生詞', 3): 'Example',\n",
    "    ('B1', ' 生詞', 4): 'ExampleP',\n",
    "    ('B1', ' 生詞', 5): 'POS',\n",
    "    ('B1', ' 生詞', 6): 'Meaning',\n",
    "    ('B1', ' 生詞', 10): 'Traditional',\n",
    "    ('B1', ' 生詞', 11): 'Pinyin',\n",
    "    ('B1', ' 生詞', 12): 'Example',\n",
    "    ('B1', ' 生詞', 13): 'ExampleP',\n",
    "    ('B1', ' 生詞', 14): 'POS',\n",
    "    ('B1', ' 生詞', 15): 'Meaning',\n",
    "    ('B1', ' 生詞', None): 'Example2',\n",
    "    ('B2', '自訂版面配置', 1): 'Traditional',\n",
    "    ('B2', '自訂版面配置', 2): 'Meaning',\n",
    "    ('B2', '自訂版面配置', 3): 'Pinyin',\n",
    "    ('B2', '生詞', 1): 'Example',\n",
    "    ('B2', '生詞', 2): 'Traditional',\n",
    "    ('B2', '生詞', 3): 'Meaning',\n",
    "    ('B2', '生詞', 4): 'Pinyin',\n",
    "    ('B2', '生詞', 10): 'Example',\n",
    "    ('B2', '生詞', 13): 'Traditional',\n",
    "    ('B2', '生詞', 15): 'Meaning',\n",
    "    ('B2', '生詞', 17): 'Pinyin',\n",
    "    ('B2', '生詞_1', 10): 'Example',\n",
    "    ('B2', '生詞_1', 13): 'Traditional',\n",
    "    ('B2', '生詞_1', 15): 'Meaning',\n",
    "    ('B2', '生詞_1', 17): 'Pinyin',\n",
    "    ('B2', '1_生詞', 13): 'Traditional',\n",
    "    ('B2', '1_生詞', 15): 'Meaning',\n",
    "    ('B2', '1_生詞', 17): 'Pinyin',\n",
    "    ('B2', '2_生詞_1', 13): 'Traditional',\n",
    "    ('B2', '2_生詞_1', 15): 'Meaning',\n",
    "    ('B2', '2_生詞_1', 17): 'Pinyin',\n",
    "    ('B2', '1_生詞_1', 13): 'Traditional',\n",
    "    ('B2', '1_生詞_1', 15): 'Meaning',\n",
    "    ('B2', '1_生詞_1', 17): 'Pinyin',\n",
    "    ('B3', '標題及內容', None): 'Freetext',\n",
    "    ('B3', 'OBJECT', None): 'Freetext',\n",
    "    ('B3', '標題投影片', None): 'TitleSlide',\n",
    "    ('B3', '4_標題投影片', None): 'TitleSlide',\n",
    "    ('B3', 'TITLE', None): 'TitleSlide',\n",
    "    ('B4', '生詞_有例句', 10): 'Example',\n",
    "    ('B4', '生詞_有例句', 13): 'Traditional',\n",
    "    ('B4', '生詞_有例句', 15): 'Meaning',\n",
    "    ('B4', '生詞_有例句', 17): 'Pinyin',\n",
    "    ('B4', '生詞_無例句', 13): 'Traditional',\n",
    "    ('B4', '生詞_無例句', 15): 'Meaning',\n",
    "    ('B4', '生詞_無例句', 17): 'Pinyin',    \n",
    "    ('B4', '生詞_無例句', 1): 'Traditional',\n",
    "    ('B4', '生詞_無例句', 2): 'Meaning',\n",
    "    ('B4', '生詞_無例句', 3): 'Pinyin',    \n",
    "    ('B4', '生詞_有例句', 1): 'Example',\n",
    "    ('B4', '生詞_有例句', 2): 'Traditional',\n",
    "    ('B4', '生詞_有例句', 3): 'Meaning',\n",
    "    ('B4', '生詞_有例句', 4): 'Pinyin',    \n",
    "    ('B4', '短語', 1): 'Traditional',\n",
    "    ('B4', '短語', 2): 'Meaning',\n",
    "    ('B4', '短語', 3): 'Pinyin',\n",
    "    ('B4', '短語', 4): 'Example',\n",
    "    ('B4', '短語', 13): 'Traditional',\n",
    "    ('B4', '短語', 15): 'Meaning',\n",
    "    ('B4', '短語', 17): 'Pinyin',\n",
    "}\n",
    "\n",
    "entries = []\n",
    "\n",
    "for lesson, filepath in PPTX_PATHS.items():\n",
    "    book = lesson[:2]\n",
    "    prs = Presentation(filepath)\n",
    "\n",
    "    for slide_i, slide in enumerate(prs.slides):\n",
    "        row = {\n",
    "            'Book': lesson[:2],\n",
    "            'Lesson': lesson,\n",
    "            'Page': slide_i+1,\n",
    "            'Layout': slide.slide_layout.name\n",
    "        }\n",
    "        \n",
    "        for shape in slide.shapes:\n",
    "            if not shape.has_text_frame:\n",
    "                continue\n",
    "\n",
    "            for paragraph in shape.text_frame.paragraphs:\n",
    "                text = ''.join(run.text for run in paragraph.runs).strip()\n",
    "                assert '\\n' not in text\n",
    "\n",
    "                if not text:\n",
    "                    continue\n",
    "\n",
    "                pidx = shape.placeholder_format.idx if shape.is_placeholder else None\n",
    "\n",
    "                field = PLACEHOLDER_MAP.get((lesson, slide.slide_layout.name, pidx))\n",
    "                if not field:\n",
    "                    field = PLACEHOLDER_MAP.get((book, slide.slide_layout.name, pidx))\n",
    "                    if not field:\n",
    "                        continue\n",
    "\n",
    "                if field == 'ExampleP':\n",
    "                    continue\n",
    "\n",
    "                if field in row:\n",
    "                    assert '<' not in text\n",
    "                    row[field] += '<br>' + text\n",
    "                else:\n",
    "                    row[field] = text\n",
    "\n",
    "        if len(row) == 5 and 'Freetext' in row and len(row['Freetext']) < 10:\n",
    "            continue\n",
    "\n",
    "        if len(row) > 4:\n",
    "            entries.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608ada4e-e252-4080-978d-88c399679b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detects spans of consecutive pages with defs and assign IDs.\n",
    "\n",
    "span = None\n",
    "spans = {}\n",
    "\n",
    "for i, row in enumerate(entries):\n",
    "    if span:\n",
    "        if row['Lesson'] == span[0] and row['Page'] == entries[i-1]['Page']+1:\n",
    "            span[2] = row['Page']\n",
    "            span[3].append(row)\n",
    "            continue\n",
    "    if span:\n",
    "        spans.setdefault(span[0], []).append(span)\n",
    "    span = [row['Lesson'], row['Page'], row['Page'], [row]]\n",
    "spans.setdefault(span[0], []).append(span)\n",
    "\n",
    "for lesson in spans:\n",
    "    #print(lesson, [s[1:3] for s in spans[lesson]])\n",
    "    assert len(spans[lesson]) <= 3\n",
    "    for span_i, span in enumerate(spans[lesson]):\n",
    "        title = None\n",
    "        k = 0\n",
    "        prev_row = None\n",
    "        for row in span[3]:\n",
    "            if 'TitleSlide' in row:\n",
    "                title = row['TitleSlide']\n",
    "                continue\n",
    "            if title:\n",
    "                row['Title'] = title\n",
    "            row['Span'] = span_i + 1\n",
    "\n",
    "            if lesson + row.get('Traditional', '') in ['B1L12事(情)', 'B1L15代表', 'B1L13壞', 'B1L12工作'] and prev_row and \\\n",
    "                prev_row['Traditional'] == row['Traditional']:\n",
    "                prev_row['Example'] = prev_row.get('Example', '') + '<br>' + row.get('Example', '')\n",
    "                row['Drop'] = 1\n",
    "                continue\n",
    "            prev_row = row\n",
    "\n",
    "            k += 1\n",
    "            row['ID'] = '%s-%d-%02d' % (row['Lesson'], row['Span'], k)\n",
    "\n",
    "entries = [row for row in entries if 'Drop' not in row]\n",
    "entries = [row for row in entries if 'TitleSlide' not in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152e239c-d0df-452d-8fe0-f8cfdc8845cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse free text on B3 slides which don't use placeholders\n",
    "\n",
    "def cn_score(text):\n",
    "    text = re.sub('([\\t0-9 （）(  ) …、/‧-]|-$)', '', text)\n",
    "    n = len(text)\n",
    "    if n == 0: return 0\n",
    "    k = sum(ord(c) >= 0x4E00 for c in text)\n",
    "    if k == 0: return 0\n",
    "    if k == n: return 1\n",
    "    return k / n\n",
    "\n",
    "ACC_POS = set(['Adv', 'Adv/ Vs-attr', 'Adv/Vs', 'Conj', 'Conj/Prep', 'Det', 'M', 'M/N', 'N',\n",
    "               'N/V', 'N/Vi', 'N/Vs', 'Phrases', 'Prep', 'Ptc', 'V', 'V-sep', 'V/N', 'V/Vi',\n",
    "               'V/Vs', 'Vaux', 'Vi', 'Vi/N', 'Vi/Vs', 'Vp', 'Vp-sep', 'Vp/N', 'Vpt', 'Vpt/N',\n",
    "               'Vs', 'Vs-attr', 'Vs-attr/Adv', 'Vs-attr/Vi', 'Vs-pred', 'Vs-sep', 'Vs/Adv',\n",
    "               'Vs/N', 'Vs/Vst', 'Vst', 'adv'])\n",
    "\n",
    "ss = []\n",
    "\n",
    "for row in entries:\n",
    "    if row['Book'] != 'B3': continue\n",
    "    text = row['Freetext'].split('<br>')\n",
    "\n",
    "    sc = [cn_score(s) for s in text]\n",
    "    if sc[:3] == [1, 1, 0]:\n",
    "        text = [text[0] + text[1]] + text[2:]\n",
    "    elif sc[:2] == [0, 0]:\n",
    "        hanzi = {'guāi': '乖', 'dǎo': '倒', 'diàochá': '調查', 'shìyě': '視野', 'shǔ': '數',\n",
    "                 'xiōngdì': '兄弟', 'wúguān': '無關', 'jiàoxué': '教學', 'bìng': '病',\n",
    "                 'wǎngyǒu': '網友', 'kòng': '空', 'kōng': '空', 'ài': '愛', 'tiānzhēn': '天真',\n",
    "                 'yǐlái': '老家', 'réngrán': '仍然'}[text[0]]\n",
    "        i = text.index(hanzi)\n",
    "        text = [hanzi] + text[:i] + text[(i+1):]\n",
    "    sc = [cn_score(s) for s in text]\n",
    "    assert sc[:3] == [1, 0, 0]\n",
    "\n",
    "    if len(text) >= 4 and text[2] not in ACC_POS and text[3] in ACC_POS:\n",
    "        text = text[:1] + [text[1] + ' ' + text[2]] + text[3:]\n",
    "    if text[2] not in ACC_POS and sum(s in ACC_POS for s in text) == 1:\n",
    "        i = [int(s in ACC_POS) for s in text].index(1)\n",
    "        assert i != 0\n",
    "        if i == 1 and any(c in 'āáǎàēéěèīíǐìōóǒòūúǔùüǘǚǜ' for c in text[-1]):\n",
    "            text = [text[0], text[-1]] + text[1:-1]\n",
    "        elif i == 1 and any(c in 'āáǎàēéěèīíǐìōóǒòūúǔùüǘǚǜ' for c in text[3]):\n",
    "            text = [text[0], text[3], text[1], text[2]] + text[4:]\n",
    "        else:\n",
    "            assert i !=1\n",
    "            text = text[:2] + [text[i]] + text[2:i] + text[(i+1):]\n",
    "\n",
    "    if text[2] not in ACC_POS:\n",
    "        for x,y in [('Wángmǔ', 'Niángniang'), ('shèqún', 'wǎngzhàn')]:\n",
    "            if x in text:\n",
    "                i = text.index(x)\n",
    "                assert i+1 == text.index(y)\n",
    "                text = text[:i] + [text[i] + ' ' + text[i+1]] + text[(i+2):]\n",
    "\n",
    "    if text[2] not in ACC_POS:\n",
    "        text = text[:2] + [''] + text[2:]\n",
    "\n",
    "    sc = [0,0,0] + [int(cn_score(s) > 0.5) for s in text[3:]]\n",
    "    if 1 in sc:\n",
    "        i = sc.index(1)\n",
    "        if i == 3:\n",
    "            assert sc[-1] == 0\n",
    "            row['Example'] = ' '.join(text[i:-1])\n",
    "            text = text[:i] + [text[-1]]\n",
    "        else:\n",
    "            row['Example'] = ' '.join(text[i:])\n",
    "            text = text[:i]\n",
    "\n",
    "    row['Traditional'] = text[0]\n",
    "    row['Pinyin'] = text[1]\n",
    "    row['POS'] = text[2]\n",
    "    row['Meaning'] = ' '.join(text[3:]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "811f5401-d285-4a1a-99d2-2155c6a90a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and normalize POS\n",
    "\n",
    "POS_MAP = {\n",
    "  '(Prep )': 'Prep',\n",
    "  '(N, V)': 'N/V',\n",
    "  '(Vi, N)': 'Vi/N',\n",
    "  '(N, Vs)': 'N/Vs',\n",
    "  '(N, M)': 'N/M',\n",
    "  '(N, V)': 'N/V',\n",
    "  '(N, V)': 'N/V',\n",
    "  '(Adv)': 'Adv',\n",
    "  '(Adv.)': 'Adv',\n",
    "  '(Adv.,Vs)': 'Adv/Vs',\n",
    "  '(Adv./Vs)': 'Adv/Vs',\n",
    "  '(Conj)': 'Conj',\n",
    "  '(Conj.)': 'Conj',\n",
    "  '(Det)': 'Det',\n",
    "  '(M)': 'M',\n",
    "  '(M,N)': 'M/N',\n",
    "  '(M/N)': 'M/N',\n",
    "  '(M/V)': 'M/V',\n",
    "  '(N)': 'N',\n",
    "  '(N,V)': 'N/V',\n",
    "  '(N,Vs-attr)': 'N/Vs-attr',\n",
    "  '(N/M)': 'N/M',\n",
    "  '(N/V)': 'N/V',\n",
    "  '(N/V-sep)': 'N/V-sep',\n",
    "  '(N/Vi)': 'N/Vi',\n",
    "  '(N/Vp-sep)': 'N/Vp-sep',\n",
    "  '(N/Vs)': 'N/Vs',\n",
    "  '(N/Vst)': 'N/Vst',\n",
    "  '(N/Vst/V)': 'N/Vst/V',\n",
    "  '(Phrase)': 'Phrase',\n",
    "  '(Prep)': 'Prep',\n",
    "  '(Prep/V/Vst)': 'Prep/V/Vst',\n",
    "  '(Ptc)': 'Ptc',\n",
    "  '(V)': 'V',\n",
    "  '(V-sep)': 'V-sep',\n",
    "  '(V-sep/N)': 'V-sep/N',\n",
    "  '(V/Adv.)': 'V/Adv',\n",
    "  '(V/N)': 'V/N',\n",
    "  '(V/Vs)': 'V/Vs',\n",
    "  '(Vaux)': 'Vaux',\n",
    "  '(Vaux/V)': 'Vaux/V',\n",
    "  '(Vi)': 'Vi',\n",
    "  '(Vi,N)': 'Vi/N',\n",
    "  '(Vi/Adv)': 'Vi/Adv',\n",
    "  '(Vi/N)': 'Vi/N',\n",
    "  '(Vi/V-sep)': 'Vi/V-sep',\n",
    "  '(Vp)': 'Vp',\n",
    "  '(Vp-sep)': 'Vp-sep',\n",
    "  '(Vp/Vpt)': 'Vp/Vpt',\n",
    "  '(Vp/Vs)': 'Vp/Vs',\n",
    "  '(Vpt)': 'Vpt',\n",
    "  '(Vpt/N)': 'Vpt/N',\n",
    "  '(Vpt/Vp)': 'Vpt/Vp',\n",
    "  '(Vs)': 'Vs',\n",
    "  '(Vs-attr / Vi)': 'Vs-attr/Vi',\n",
    "  '(Vs-attr/Vp)': 'Vs-attr/Vp',\n",
    "  '(Vs-attr)': 'Vs-attr',\n",
    "  '(Vs-attr/Adv.)': 'Vs-attr/Adv',\n",
    "  '(Vs-attr/Vp)': 'Vs-attr/Vp',\n",
    "  '(Vs-pred)': 'Vs-pred',\n",
    "  '(Vs-sep)': 'Vs-sep',\n",
    "  '(Vs/V)': 'Vs/V',\n",
    "  '(Vs/Vst)': 'Vs/Vst',\n",
    "  '(Vst)': 'Vst',\n",
    "  '(Vst/N)': 'Vst/N',\n",
    "  '(Vst/Prep)': 'Vst/Prep',\n",
    "  '(Vst/Vs/Adv./Vi)': 'Vst/Vs/Adv/Vi',\n",
    "  '（Det)': 'Det',\n",
    "  '(Vs-attr, N)': 'Vs-attr/N',\n",
    "\n",
    "  '(Vs-attr': 'Vs-attr',\n",
    "  '(Vs-attr,': 'Vs-attr,',\n",
    "}\n",
    "POS_REMAP = {\n",
    "  'Names': 'Name',\n",
    "  'Phrase': 'Ph',\n",
    "  'phrase': 'Ph',\n",
    "  'Phrases': 'Ph',\n",
    "  'VS': 'Vs',\n",
    "  'Vs-attr,': 'Vs-attr',\n",
    "  'adv': 'Adv',\n",
    "  'Cong': 'Conj',\n",
    "  'Adv/ Vs-attr': 'Adv/Vs-attr',\n",
    "  'V-sep/ N': 'V-sep/N',\n",
    "}\n",
    "\n",
    "for row in entries:\n",
    "    text = row.get('Meaning', '').replace('<br>', ' ').strip()\n",
    "    text0 = text\n",
    "    pos = ''\n",
    "    for pref in POS_MAP:\n",
    "        if text.startswith(pref):\n",
    "            pos = POS_MAP[pref]\n",
    "            text = text[len(pref):]\n",
    "    if not pos and 'measure' in text.lower() or 'classifier' in text.lower():\n",
    "        pos = 'M'\n",
    "    if not pos and not row.get('POS') and row.get('Title') == 'Phrase':\n",
    "        pos = 'Phrase'\n",
    "    if not pos and not row.get('POS') and row.get('Title') == 'Names':\n",
    "        pos = 'Name'\n",
    "    if pos:\n",
    "        assert row.get('POS', pos) in (pos, ''), (row, pos)\n",
    "        row['POS'] = pos\n",
    "    pos = row.get('POS', '')\n",
    "    pos = pos.strip()\n",
    "    pos = POS_REMAP.get(pos, pos)\n",
    "    row['POS'] = pos\n",
    "    text = text.strip()\n",
    "    row['Meaning'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e495feb9-5f56-4764-8a47-14a2e1ee61fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4061"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup/normalize entries\n",
    "\n",
    "for row in entries:\n",
    "    if not row.get('Meaning') and row['Traditional'] == '保護':\n",
    "        row['POS'], row['Meaning'] = 'V', 'to protect'\n",
    "    if not row.get('Pinyin'):\n",
    "        row['Pinyin'] = {'隻': 'zhī', 'KTV': 'KTV'}[row['Traditional']]\n",
    "    if not row.get('Traditional'):\n",
    "        row['Traditional'] = {'yìnzhāng/túzhāng': '印章/圖章'}[row['Pinyin']]\n",
    "\n",
    "    trad = row['Traditional']\n",
    "    for x, y in (('<br>', ''), (' ', ''), (',', '，'), ('（', '('), ('）', ')'), ('／', '/'), ('∕', '/'), ('。', '')):\n",
    "        trad = trad.replace(x, y).strip()\n",
    "    trad = {\n",
    "        '你/妳好': '你好/妳好',\n",
    "        '夜裡(裏)': '夜裡',\n",
    "        '裡頭/裏頭': '裡頭',\n",
    "        '計畫/劃': '計畫/計劃',\n",
    "        '部分/份': '部分/部份',\n",
    "        '健康檢查(健檢)': '健康檢查/健檢',\n",
    "    }.get(trad, trad)\n",
    "    assert re.match(r'^([\\u4e00-\\u9fff()，/]|KTV|101|卡拉OK|3C產品|……|？$)+$', trad)\n",
    "    row['Traditional'] = trad\n",
    "\n",
    "    pinyin = row['Pinyin']\n",
    "    for x, y in (('<br>', ' '), ('\\t', ' '), (' ', ' '), ('\\u200b', ' '), ('\\ufeff', ' '),\n",
    "                 ('\\u00a0', ' '), ('  ', ' '), (' , ', ', '), ('’', \"'\"), (' / ', '/'),\n",
    "                 ('/ ', '/'), (' /', '/'), (' \\ ', '/'), (' ?', '?'), ('‑', ' '),\n",
    "                 ('-', ' '), ('ă', 'ǎ'), ('ĕ', 'ě'), ('ĭ', 'ǐ'), ('ŏ', 'ǒ'), ('ŭ', 'ǔ'),\n",
    "                 ('ǎ', 'ǎ'), ('a\\u030c', 'ǎ'), ('e\\u030c', 'ě'),\n",
    "                 (' (miàn)', '(miàn)'), (' (qíng)', '(qíng)'), (' (zi)', '(zi)'),\n",
    "                 (' (jī)', '(jī)'), ('yèlǐ (lǐ)', 'yèlǐ'), (' (zhe)', '(zhe)'),\n",
    "                 (' (cháng)', '(cháng)'), ('Xīngqí tiān', 'xīngqítiān'),\n",
    "                 ('Jiànkāngjiǎnchá(jiànjiǎn)', 'Jiànkāngjiǎnchá/jiànjiǎn'),\n",
    "                ):\n",
    "        pinyin = pinyin.replace(x, y).strip()\n",
    "    m = re.match(r\"^([a-zāáǎàēéěèīíǐìōóǒòūúǔùüǘǚǜ/ '()]|\\b, |3c |[?]$|……)+$\", pinyin.lower())\n",
    "    if not m: print(pinyin)\n",
    "    assert m\n",
    "    row['Pinyin'] = pinyin\n",
    "\n",
    "    ex = row.get('Examples', row.get('Example', ''))\n",
    "    if row.get('Example2'):\n",
    "        for s in row['Example2'].split('<br>'):\n",
    "            s = s.strip()\n",
    "            if len(s) >= 2 and cn_score(s) > 0.5:\n",
    "                if ex: ex += '<br>'\n",
    "                ex += s\n",
    "    ex = re.sub(r'(<br>)+', '<br>', ex).strip()\n",
    "    ex = re.sub(r'^(<br>)+', '', ex).strip()\n",
    "    ex = re.sub(r'(<br>)+$', '', ex).strip()\n",
    "    ex = re.sub(r'([\\t \\u200b\\ufeff\\u00a0])+', ' ', ex).strip()\n",
    "    row['Examples'] = ex\n",
    "    if 'Example' in row: del row['Example']\n",
    "    if 'Example2' in row: del row['Example2']\n",
    "\n",
    "    row.setdefault('POS', '')\n",
    "\n",
    "    for col in ['Traditional', 'Pinyin', 'Meaning', 'POS', 'Examples']:\n",
    "        row[col] = row[col].strip()\n",
    "    for col in ['Traditional', 'Pinyin', 'Meaning']:\n",
    "        assert row[col]\n",
    "\n",
    "    text = row['Meaning']\n",
    "    for x, y in [\n",
    "        (r'([\\t \\u200b\\ufeff\\u00a0])+', ' '),\n",
    "        (r'“(.*)’’', r'\"\\1\"'),\n",
    "        ('’', \"'\"), ('‘', \"'\"), ('’', \"'\"), \n",
    "        ('”;', '\";'), ('”[.]', '\".'), ('”=', '\"='), ('“of ”', '\"of\"'), ('“', ' \"'), ('”', '\" '),\n",
    "        ('ﬃ', 'ffi'), ('ﬄ', 'ffl'), ('ﬁ', 'fi'), ('ﬂ', 'fl'), ('ﬀ', 'ff'),\n",
    "        ('…[.]{3}', '...'), ('…', '...'),\n",
    "        (' *[(] *M[:：] *', ' (M: '), (' *： *', ': '), (' *； *', '; '),\n",
    "        ('、 *', ', '),\n",
    "        ('  +', ' '),\n",
    "        ('（', ' ('), ('）', ') '),\n",
    "        (' [)] , ', '), '), (' ([:;,]) ', r'\\1 '),\n",
    "        (' ,([a-z])', r', \\1'),\n",
    "        (r'\\.\\.\\., *', '..., '),\n",
    "        ('([a-z)])([,;:])([a-z])', r'\\1\\2 \\3'),\n",
    "        ('([a-z])([(])([a-z])', r'\\1 (\\3'), ('([a-z])([)])([a-z])', r'\\1) \\3'),\n",
    "        ('[(] *', '('), (' *[)]', ')'),\n",
    "        ('！,ah', '! ah'), ('！', '! '), (' *! *', '! '), ('! \"', '!\"'), ('!,', '!, '),\n",
    "        (r'\\(someone~\\)', '(someone)'), (r'\\[foolishly\\]', '(foolishly)'),\n",
    "        ('^N[)] ', ''),\n",
    "        ('ă', 'ǎ'), ('ĕ', 'ě'), ('ĭ', 'ǐ'), ('ŏ', 'ǒ'), ('ŭ', 'ǔ'), ('ǎ', 'ǎ'), ('a\\u030c', 'ǎ'), ('e\\u030c', 'ě'),\n",
    "        ('^[)] *', ''),\n",
    "        ('^To ', 'to '),\n",
    "        (' +', ' '),\n",
    "    ]:\n",
    "        text = re.sub(x, y, text).strip()\n",
    "    m = re.match(r'''^([-a-z0-9āáǎàēéěèīíǐìōóǒòūúǔùüǘǚǜ ,.:;!?+&/=()\"'\\u4e00-\\u9fff])+$''', text.lower())\n",
    "    if not m: print(text)\n",
    "    assert m\n",
    "    row['Meaning'] = text\n",
    "\n",
    "    row['Simplified'] = opencc_tw2s.convert(row['Traditional'])\n",
    "\n",
    "    row['Tags'] = ''\n",
    "    if re.match('.*([/()]).*', row['Traditional']):\n",
    "        row['Tags'] = 'Variants'\n",
    "        trad = row['Traditional']\n",
    "        expanded = []\n",
    "        for s in trad.split('/'):\n",
    "            if '(' in s:\n",
    "                expanded.extend([re.sub('[(][^)]*[)]', '', s), re.sub('[()]', '', s)])\n",
    "            else:\n",
    "                expanded.append(s)\n",
    "        expanded = {\n",
    "            '你/妳好': ['你好', '妳好'],\n",
    "            '有(一)點(兒)': ['有點', '有一點','有點兒', '有一點兒'],\n",
    "            '(一)點(兒)': ['一點', '點', '一點兒', '點兒'],\n",
    "            '計畫/劃': ['計畫', '計劃'],\n",
    "            '部分/份': ['部分', '部份'],\n",
    "            '白白/白(白)': ['白白', '白'],\n",
    "        }.get(trad, expanded)\n",
    "        row['TraditionalExpanded'] = '/'.join(expanded)\n",
    "    else:\n",
    "        row['TraditionalExpanded'] = row['Traditional']\n",
    "\n",
    "    audio = ''\n",
    "    if os.path.exists(TTS_MP3_PATTERN % row['ID']):\n",
    "        audio = '[sound:%s]' % os.path.basename(TTS_MP3_PATTERN % row['ID'])\n",
    "    row['Audio'] = audio\n",
    "\n",
    "df = pd.DataFrame(entries)\n",
    "assert list(df.ID) == list(sorted(df.ID))\n",
    "cols = ['ID', 'Traditional', 'Simplified', 'Pinyin', 'POS', 'Meaning', 'Examples', 'Audio', 'TraditionalExpanded', 'Tags']\n",
    "#cols += [c for c in df if c not in cols]\n",
    "df = df[cols].set_index('ID').copy()\n",
    "df.to_csv('modernchinese.tsv', sep='\\t', index=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "783ebe72-1d7d-4d78-b880-3d24cd09cebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 100363485 Oct  7 08:32 modernchinese.apkg\n"
     ]
    }
   ],
   "source": [
    "# Generate anki package\n",
    "\n",
    "cols = ['ID', 'Traditional', 'Simplified', 'Pinyin', 'POS', 'Meaning', 'Examples', 'Audio']\n",
    "\n",
    "model = genanki.Model(\n",
    "    1696565462,\n",
    "    'ModernChinese',\n",
    "    fields=[{'name': c} for c in cols],\n",
    "    templates=[{\n",
    "        'name': 'ModernChinese',\n",
    "        'qfmt': open('../dangdai/dangdai-qfmt.html').read(),\n",
    "        'afmt': open('../dangdai/dangdai-afmt.html').read().replace(\n",
    "            '<div>{{Audio}}</div>',\n",
    "            '<div>{{Audio}}</div>\\n<br>\\n<div>{{Examples}}</div>')\n",
    "    }],\n",
    "    css=open('../dangdai/dangdai.css').read(),\n",
    ")\n",
    "\n",
    "deck = genanki.Deck(1696565463, name='modernchinese', description='Modern Chinese vocabulary deck')\n",
    "\n",
    "for row in df.reset_index()[cols].to_records(index=False):\n",
    "    tags = df.loc[row[0], 'Tags'].split()\n",
    "    deck.add_note(genanki.Note(model=model, fields=row, tags=tags))\n",
    "\n",
    "media = list(set(df.Audio.str.extract('sound:(.*.mp3)')[0])) + ['_MoeStandardKai.ttf']\n",
    "media = [os.path.join(MEDIA_DIR, s) for s in media]\n",
    "!rm -f modernchinese.apkg\n",
    "genanki.Package(deck, media_files=media).write_to_file('modernchinese.apkg')\n",
    "!ls -l modernchinese.apkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c6a9318-f3ce-425c-b5a7-3db79fb3fda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 617940 Oct  7 08:32 modernchinese_pleco.txt\n"
     ]
    }
   ],
   "source": [
    "# Also export in pleco's flashcard / user dictionary format\n",
    "\n",
    "with open('modernchinese_pleco.txt', 'w') as fout:\n",
    "    last_header = ''\n",
    "    for row in df.itertuples():\n",
    "        m = re.match('^B([1-4])(L[0-9]{2}-[1-3])-.*', row.Index)\n",
    "        header = f'//時代華語/Book {m[1]}/{m[2]}'\n",
    "        if header != last_header:\n",
    "            fout.write(header + '\\n')\n",
    "            last_header = header\n",
    "\n",
    "        if row.POS:\n",
    "            defn = f'({row.POS}) {row.Meaning}'\n",
    "        else:\n",
    "            defn = row.Meaning\n",
    "\n",
    "        text = f'{row.Simplified}[{row.Traditional}]\\t{row.Pinyin}\\t{defn}'\n",
    "        if row.Examples:\n",
    "            text += '\\uEAB1'  # new line\n",
    "            text += '\\uEAC1\\uEC00\\uEC05\\uECAA\\uECFF'  # text color 05AAFF, light blue\n",
    "            text += row.Examples \\\n",
    "                .replace('<br>', '\\uEAB1') \\\n",
    "                .replace(\n",
    "                    row.Traditional,\n",
    "                    # highlight term with #05BBBB teal\n",
    "                    '\\uEAC2\\uEAC1\\uEC00\\uEC05\\uECBB\\uECBB' +\n",
    "                    row.Traditional +\n",
    "                    '\\uEAC2\\uEAC1\\uEC00\\uEC05\\uECAA\\uECFF'\n",
    "                )\n",
    "            text += '\\uEAC2' # end of text color\n",
    "            assert '\\n' not in row.Examples\n",
    "        fout.write(text + '\\n')\n",
    "\n",
    "!ls -l modernchinese_pleco.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
